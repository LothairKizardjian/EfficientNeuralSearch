2019-09-09 16:34:47.858335: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 16:34:47.891067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 16:34:48.181716: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46cac50 executing computations on platform CUDA. Devices:
2019-09-09 16:34:48.181789: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 16:34:48.205094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 16:34:48.206613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43a76a0 executing computations on platform Host. Devices:
2019-09-09 16:34:48.206662: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 16:34:48.208377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 16:34:48.208834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 16:34:48.211397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 16:34:48.213527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 16:34:48.214051: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 16:34:48.217076: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 16:34:48.218961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 16:34:48.224611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 16:34:48.228283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 16:34:48.228353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 16:34:48.230043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 16:34:48.230076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 16:34:48.230090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 16:34:48.233546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 16:34:48.234693 140073800849216 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 8669521010036013475
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 13665061513369531176
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 7503937285456073491
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 13374192657367602949
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading games for pgn chess_games_2003 ...
1000 games loaded
loading tensors and according labels ...
Loading data for chess_games_2004
Loading games for pgn chess_games_2004 ...
1000 games loaded
loading tensors and according labels ...
42876
Loading data ...
Loading data for chess_games_2005
Loading games for pgn chess_games_2005 ...
1000 games loaded
loading tensors and according labels ...
--------------------------------------------------------------------------------
Build model child
Build data ops
W0909 16:36:54.367503 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0909 16:36:59.463539 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 16:36:59.465669 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 16:36:59.533420 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0909 16:37:00.244236 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0909 16:37:01.322695 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0909 16:37:01.323472 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0909 16:37:01.431697 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0909 16:37:01.526556 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0909 16:37:05.766565 140073800849216 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0909 16:37:05.782546 140073800849216 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0909 16:37:05.806559 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0909 16:37:05.989675 140073800849216 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0909 16:37:06.139519 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-09 16:37:07.575369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 16:37:07.575455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 16:37:07.575479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 16:37:07.575502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 16:37:07.575522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 16:37:07.575548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 16:37:07.575568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 16:37:07.575588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 16:37:07.579687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 16:37:07.579778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 16:37:07.579809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 16:37:07.579822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 16:37:07.583264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0909 16:37:09.243517 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0909 16:37:09.346338 140073800849216 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0909 16:37:30.802047 140073800849216 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Traceback (most recent call last):
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 527, in _apply_op_helper
    preferred_dtype=default_dtype)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1018, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor("Log_11:0", shape=(?,), dtype=float64)'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "src/chess/main.py", line 395, in <module>
    tf.app.run()
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "src/chess/main.py", line 384, in main
    train()
  File "src/chess/main.py", line 235, in train
    ops = get_ops(images, labels)
  File "src/chess/main.py", line 182, in get_ops
    child_model.connect_controller(controller_model)
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py", line 879, in connect_controller
    self._build_train()
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py", line 759, in _build_train
    log_probs = tf.keras.backend.categorical_crossentropy(target=logits, output=self.y_train, axis=1)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py", line 4149, in categorical_crossentropy
    return -math_ops.reduce_sum(target * math_ops.log(output), axis)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 884, in binary_op_wrapper
    return func(x, y, name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1180, in _mul_dispatch
    return gen_math_ops.mul(x, y, name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 6490, in mul
    "Mul", x=x, y=y, name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 563, in _apply_op_helper
    inferred_from[input_arg.type_attr]))
TypeError: Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'.
Exception ignored in: <src.utils.Logger object at 0x7f6513fbbeb8>
AttributeError: 'Logger' object has no attribute 'flush'
2019-09-10 14:00:59.176138: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-10 14:00:59.255790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-10 14:00:59.523196: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x545acd0 executing computations on platform CUDA. Devices:
2019-09-10 14:00:59.523269: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-10 14:00:59.545065: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-10 14:00:59.546223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5137910 executing computations on platform Host. Devices:
2019-09-10 14:00:59.546268: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-10 14:00:59.565608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:00:59.582749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:00:59.617994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:00:59.627250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:00:59.640399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:00:59.650072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:00:59.661733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:00:59.722175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:00:59.725735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:00:59.725808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:00:59.727491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:00:59.727523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:00:59.727535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:00:59.730404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0910 14:00:59.731610 139792307939136 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 17096485394454552002
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 4221694425841452989
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 14375465599071198394
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 17451133756947947280
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
42876
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0910 14:01:07.506862 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0910 14:01:12.380019 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0910 14:01:12.382175 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0910 14:01:12.523934 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0910 14:01:13.232748 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0910 14:01:14.360740 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0910 14:01:14.361593 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0910 14:01:14.469457 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0910 14:01:14.562465 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0910 14:01:16.604959 139792307939136 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0910 14:01:16.620919 139792307939136 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0910 14:01:16.644027 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0910 14:01:16.829655 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0910 14:01:17.006393 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-10 14:01:18.205119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:01:18.205210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:01:18.205233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:01:18.205255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:01:18.205274: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:01:18.205300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:01:18.205337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:01:18.205360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:01:18.207738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:01:18.207813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:01:18.207831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:01:18.207841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:01:18.210662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0910 14:01:19.905388 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0910 14:01:20.010482 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0910 14:01:41.412299 139792307939136 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
@@@@@@@@@@@@@@@@@@@@@@@@
Tensor("child/fc/MatMul:0", shape=(?, 1), dtype=float32)
Tensor("shuffle_batch:1", shape=(?,), dtype=float32, device=/device:CPU:0)
@@@@@@@@@@@@@@@@@@@@@@@@
Model has 315216 params
W0910 14:02:11.139120 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:173: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0910 14:02:11.169386 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:213: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

--------------------------------------------------------------------------------
Build valid graph
Tensor("child_1/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build test graph
Tensor("child_2/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build valid graph on shuffled data
Tensor("child_3/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
<tf.Variable 'controller/lstm/layer_0/w:0' shape=(128, 256) dtype=float32_ref>
<tf.Variable 'controller/g_emb:0' shape=(1, 64) dtype=float32_ref>
<tf.Variable 'controller/emb/w:0' shape=(6, 64) dtype=float32_ref>
<tf.Variable 'controller/softmax/w:0' shape=(64, 6) dtype=float32_ref>
<tf.Variable 'controller/attention/w_1:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/w_2:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/v:0' shape=(64, 1) dtype=float32_ref>
W0910 14:02:51.147325 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:185: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0910 14:02:51.159950 139792307939136 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:218: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0910 14:02:51.160237 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:231: SyncReplicasOptimizer.__init__ (from tensorflow.python.training.sync_replicas_optimizer) is deprecated and will be removed in a future version.
Instructions for updating:
The `SyncReplicaOptimizer` class is deprecated. For synchrononous training, please use [Distribution Strategies](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).
I0910 14:02:51.160387 139792307939136 sync_replicas_optimizer.py:188] SyncReplicasV2: replicas_to_aggregate=20; total_num_replicas=1
W0910 14:02:53.287879 139792307939136 deprecation_wrapper.py:119] From src/chess/main.py:239: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0910 14:02:55.663268 139792307939136 deprecation_wrapper.py:119] From src/chess/main.py:240: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.

I0910 14:02:55.663557 139792307939136 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
--------------------------------------------------------------------------------
Starting session
I0910 14:03:35.414360 139792307939136 monitored_session.py:240] Graph was finalized.
2019-09-10 14:03:35.417270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:03:35.417397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:03:35.417432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:03:35.417457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:03:35.417481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:03:35.417506: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:03:35.417532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:03:35.417560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:03:35.419679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:03:35.419745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:03:35.419761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:03:35.419772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:03:35.422124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-09-10 14:03:45.065733: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0910 14:03:50.288498 139792307939136 session_manager.py:500] Running local_init_op.
I0910 14:03:51.763890 139792307939136 session_manager.py:502] Done running local_init_op.
W0910 14:03:56.365598 139792307939136 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
2019-09-10 14:15:29.865173: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-10 14:15:30.050419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-10 14:15:30.462424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a9e950 executing computations on platform CUDA. Devices:
2019-09-10 14:15:30.462514: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-10 14:15:30.649086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-10 14:15:30.650650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x477bcc0 executing computations on platform Host. Devices:
2019-09-10 14:15:30.650699: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-10 14:15:30.652687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:15:30.721467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:15:30.878825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:15:30.964834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:15:30.996673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:15:31.151342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:15:31.277630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:15:31.621264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:15:31.625071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:15:31.640148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:15:31.657556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:15:31.657611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:15:31.657629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:15:31.682312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0910 14:15:31.700727 140226417461056 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 2412463792238259604
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 567343783919017137
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 9558984153367149231
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 2769282305070807743
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading games for pgn chess_games_2000 ...
200 games loaded
loading tensors and according labels ...
Loading data for chess_games_2001
Loading games for pgn chess_games_2001 ...
200 games loaded
loading tensors and according labels ...
Loading data for chess_games_2002
Loading games for pgn chess_games_2002 ...
200 games loaded
loading tensors and according labels ...
Loading data for chess_games_2003
Loading games for pgn chess_games_2003 ...
200 games loaded
loading tensors and according labels ...
Loading data for chess_games_2004
Loading games for pgn chess_games_2004 ...
200 games loaded
loading tensors and according labels ...
8446
Loading data ...
Loading data for chess_games_2005
Loading games for pgn chess_games_2005 ...
200 games loaded
loading tensors and according labels ...
--------------------------------------------------------------------------------
Build model child
Build data ops
W0910 14:16:21.682719 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0910 14:16:22.690914 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0910 14:16:22.692803 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0910 14:16:22.904724 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0910 14:16:23.059876 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0910 14:16:23.245116 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0910 14:16:23.245888 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0910 14:16:23.353712 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0910 14:16:23.446670 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0910 14:16:28.892485 140226417461056 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0910 14:16:28.948727 140226417461056 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0910 14:16:28.971786 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0910 14:16:29.157077 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0910 14:16:29.406969 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-10 14:16:30.499808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:16:30.499900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:16:30.499922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:16:30.499942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:16:30.499964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:16:30.499984: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:16:30.500005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:16:30.500026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:16:30.502632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:16:30.502703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:16:30.502718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:16:30.502733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:16:30.505801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0910 14:16:36.872024 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0910 14:16:36.978900 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0910 14:16:57.954703 140226417461056 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
@@@@@@@@@@@@@@@@@@@@@@@@
Tensor("child/fc/Tanh:0", shape=(?, 1), dtype=float32)
Tensor("shuffle_batch:1", shape=(?,), dtype=float32, device=/device:CPU:0)
@@@@@@@@@@@@@@@@@@@@@@@@
Model has 315216 params
W0910 14:17:27.554292 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:173: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0910 14:17:27.584347 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:213: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

--------------------------------------------------------------------------------
Build valid graph
Tensor("child_1/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build test graph
Tensor("child_2/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build valid graph on shuffled data
Tensor("child_3/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
<tf.Variable 'controller/lstm/layer_0/w:0' shape=(128, 256) dtype=float32_ref>
<tf.Variable 'controller/g_emb:0' shape=(1, 64) dtype=float32_ref>
<tf.Variable 'controller/emb/w:0' shape=(6, 64) dtype=float32_ref>
<tf.Variable 'controller/softmax/w:0' shape=(64, 6) dtype=float32_ref>
<tf.Variable 'controller/attention/w_1:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/w_2:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/v:0' shape=(64, 1) dtype=float32_ref>
W0910 14:18:06.980074 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:185: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0910 14:18:06.992600 140226417461056 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:218: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0910 14:18:06.992875 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:231: SyncReplicasOptimizer.__init__ (from tensorflow.python.training.sync_replicas_optimizer) is deprecated and will be removed in a future version.
Instructions for updating:
The `SyncReplicaOptimizer` class is deprecated. For synchrononous training, please use [Distribution Strategies](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).
I0910 14:18:06.993051 140226417461056 sync_replicas_optimizer.py:188] SyncReplicasV2: replicas_to_aggregate=20; total_num_replicas=1
W0910 14:18:09.121308 140226417461056 deprecation_wrapper.py:119] From src/chess/main.py:239: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0910 14:18:11.479221 140226417461056 deprecation_wrapper.py:119] From src/chess/main.py:240: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.

I0910 14:18:11.479511 140226417461056 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
--------------------------------------------------------------------------------
Starting session
I0910 14:18:35.838102 140226417461056 monitored_session.py:240] Graph was finalized.
2019-09-10 14:18:35.840665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-10 14:18:35.840748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-10 14:18:35.840792: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:18:35.840818: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-10 14:18:35.840846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-10 14:18:35.840867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-10 14:18:35.840888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-10 14:18:35.840908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-10 14:18:35.844221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-10 14:18:35.844290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-10 14:18:35.844307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-10 14:18:35.844317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-10 14:18:35.846629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-09-10 14:18:45.158483: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0910 14:18:50.445842 140226417461056 session_manager.py:500] Running local_init_op.
I0910 14:18:51.846273 140226417461056 session_manager.py:502] Done running local_init_op.
W0910 14:18:56.330581 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
I0910 14:20:58.749922 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 0 into outputs/model.ckpt.
2019-09-10 14:21:39.644999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-10 14:21:40.916781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
epoch=0     ch_step=50     loss=-1160.503174 lr=0.0500   |g|=0.3087   tr_acc=17 /128 mins=0.44      
epoch=0     ch_step=100    loss=-1192.739380 lr=0.0500   |g|=0.3064   tr_acc=21 /128 mins=0.51      
epoch=0     ch_step=150    loss=-1267.853516 lr=0.0500   |g|=0.3026   tr_acc=24 /128 mins=0.58      
epoch=0     ch_step=200    loss=-1276.444336 lr=0.0500   |g|=0.2989   tr_acc=28 /128 mins=0.65      
epoch=0     ch_step=250    loss=-1237.045044 lr=0.0500   |g|=0.2951   tr_acc=21 /128 mins=0.72      
epoch=0     ch_step=300    loss=-1192.739380 lr=0.0500   |g|=0.2915   tr_acc=21 /128 mins=0.80      
epoch=0     ch_step=350    loss=-1291.869385 lr=0.0500   |g|=0.2878   tr_acc=30 /128 mins=0.87      
epoch=0     ch_step=400    loss=-1254.374390 lr=0.0500   |g|=0.2843   tr_acc=22 /128 mins=0.94      
epoch=0     ch_step=450    loss=-1253.624756 lr=0.0500   |g|=0.2812   tr_acc=21 /128 mins=1.01      
epoch=0     ch_step=500    loss=-1265.140503 lr=0.0500   |g|=0.2777   tr_acc=23 /128 mins=1.08      
epoch=0     ch_step=550    loss=-1237.045044 lr=0.0500   |g|=0.2742   tr_acc=21 /128 mins=1.15      
I0910 14:22:37.352888 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 594 into outputs/model.ckpt.
Epoch 1: Training controller
ctrl_step=0      loss=8.586   ent=26.45 lr=0.0010 |g|=0.2001   acc=0.1250 bl=0.00  mins=1.50
ctrl_step=2      loss=5.446   ent=26.45 lr=0.0010 |g|=0.0612   acc=0.1250 bl=0.05  mins=1.55
ctrl_step=5      loss=7.728   ent=26.46 lr=0.0010 |g|=0.1091   acc=0.1875 bl=0.08  mins=1.59
ctrl_step=7      loss=2.200   ent=26.45 lr=0.0010 |g|=0.0671   acc=0.1250 bl=0.10  mins=1.63
ctrl_step=10     loss=2.420   ent=26.46 lr=0.0010 |g|=0.0282   acc=0.1406 bl=0.11  mins=1.67
ctrl_step=12     loss=1.817   ent=26.46 lr=0.0010 |g|=0.0401   acc=0.1406 bl=0.12  mins=1.71
ctrl_step=15     loss=5.667   ent=26.45 lr=0.0010 |g|=0.0723   acc=0.2031 bl=0.12  mins=1.76
ctrl_step=17     loss=0.141   ent=26.45 lr=0.0010 |g|=0.0360   acc=0.1250 bl=0.13  mins=1.80
ctrl_step=20     loss=-1.934  ent=26.47 lr=0.0010 |g|=0.0661   acc=0.0938 bl=0.13  mins=1.84
ctrl_step=22     loss=2.333   ent=26.48 lr=0.0010 |g|=0.0250   acc=0.1562 bl=0.13  mins=1.88
ctrl_step=25     loss=0.641   ent=26.44 lr=0.0010 |g|=0.0453   acc=0.1328 bl=0.13  mins=1.92
ctrl_step=27     loss=0.003   ent=26.44 lr=0.0010 |g|=0.0369   acc=0.1250 bl=0.13  mins=1.97
ctrl_step=30     loss=0.486   ent=26.44 lr=0.0010 |g|=0.0486   acc=0.1328 bl=0.13  mins=2.01
ctrl_step=32     loss=1.545   ent=26.43 lr=0.0010 |g|=0.0676   acc=0.1484 bl=0.13  mins=2.05
ctrl_step=35     loss=-0.051  ent=26.50 lr=0.0010 |g|=0.0517   acc=0.1250 bl=0.13  mins=2.09
ctrl_step=37     loss=-0.127  ent=26.45 lr=0.0010 |g|=0.0493   acc=0.1250 bl=0.13  mins=2.13
ctrl_step=40     loss=-2.789  ent=26.46 lr=0.0010 |g|=0.0941   acc=0.0859 bl=0.13  mins=2.18
ctrl_step=42     loss=2.502   ent=26.39 lr=0.0010 |g|=0.1107   acc=0.1641 bl=0.13  mins=2.22
ctrl_step=45     loss=1.549   ent=26.42 lr=0.0010 |g|=0.0755   acc=0.1484 bl=0.13  mins=2.26
ctrl_step=47     loss=-1.080  ent=26.45 lr=0.0010 |g|=0.0707   acc=0.1094 bl=0.13  mins=2.30
Here are 10 architectures
[3]
[1 0]
[0 0 0]
[0 0 1 1]
[5 1 0 1 0]
[1 0 0 0 0 0]
[4 0 0 1 1 1 1]
[5 1 0 0 0 1 0 0]
[4 0 1 0 0 1 1 0 0]
[0 1 0 1 1 1 0 0 0 1]
[2 0 1 1 0 0 1 1 0 1 0]
[2 0 1 1 0 1 0 0 0 1 1 0]
val_acc=0.0859
--------------------------------------------------------------------------------
[0]
[5 1]
[4 1 1]
[2 0 1 0]
[2 0 1 0 0]
[2 0 0 1 1 1]
[1 0 1 1 0 0 0]
[0 0 1 0 0 1 0 0]
[0 1 1 0 1 1 1 0 0]
[0 0 0 0 1 1 1 1 1 1]
[4 1 0 1 0 1 0 0 0 0 1]
[3 1 1 1 0 0 1 0 0 1 1 0]
val_acc=0.1641
--------------------------------------------------------------------------------
[2]
[2 1]
[5 1 0]
[0 1 1 0]
[0 0 0 0 0]
[4 0 0 1 0 1]
[4 0 0 1 0 0 1]
[3 0 0 1 0 0 0 0]
[3 0 1 0 0 1 1 1 0]
[2 1 1 1 0 0 0 0 0 0]
[5 1 1 0 0 1 1 0 0 1 0]
[0 1 1 1 1 1 1 0 1 1 1 1]
val_acc=0.1484
--------------------------------------------------------------------------------
[5]
[0 1]
[1 1 0]
[0 0 0 1]
[1 1 0 1 0]
[1 1 1 1 0 1]
[1 0 1 1 0 0 1]
[2 0 0 1 1 1 1 1]
[1 0 0 0 0 1 0 1 0]
[3 0 1 1 1 1 1 0 0 1]
[4 1 1 1 1 1 0 1 1 0 1]
[2 0 0 0 1 1 0 1 0 1 1 1]
val_acc=0.1875
--------------------------------------------------------------------------------
[4]
[3 0]
[4 1 1]
[2 0 0 1]
[4 1 0 1 0]
[2 0 0 0 1 1]
[0 1 0 0 0 0 1]
[3 0 0 1 1 1 0 1]
[1 0 0 0 1 1 1 0 0]
[0 0 0 1 1 1 0 1 1 0]
[2 0 1 1 1 0 0 0 1 1 0]
[1 0 0 1 1 0 1 1 1 1 1 1]
val_acc=0.0938
--------------------------------------------------------------------------------
[4]
[4 0]
[5 0 1]
[1 1 0 0]
[5 0 1 0 1]
[4 0 1 0 1 0]
[2 0 0 0 0 0 1]
[0 1 0 1 1 1 1 1]
[5 0 0 0 0 1 1 0 1]
[1 0 0 0 1 1 0 0 0 0]
[3 0 0 1 0 1 0 1 1 1 1]
[0 1 0 0 1 1 0 0 0 1 0 1]
val_acc=0.1406
--------------------------------------------------------------------------------
[1]
[2 1]
[0 1 0]
[3 0 1 0]
[1 1 1 1 1]
[4 1 0 1 1 1]
[5 1 1 1 1 1 0]
[3 0 0 0 1 1 0 0]
[4 0 0 0 1 1 0 1 0]
[1 1 0 0 0 0 1 0 1 0]
[3 0 1 0 1 0 0 1 0 0 0]
[2 1 0 1 1 1 0 1 0 1 0 1]
val_acc=0.0938
--------------------------------------------------------------------------------
[0]
[4 0]
[0 0 1]
[1 1 0 0]
[2 1 1 1 0]
[2 1 1 1 0 1]
[1 1 1 1 0 1 1]
[3 1 0 1 1 1 0 0]
[1 1 0 0 0 1 0 1 1]
[5 0 0 1 0 0 0 0 1 0]
[1 0 0 0 0 1 0 0 1 0 0]
[3 1 0 0 0 1 1 0 0 1 0 1]
val_acc=0.1562
--------------------------------------------------------------------------------
[3]
[5 1]
[1 1 0]
[0 0 0 0]
[3 1 1 1 0]
[3 0 0 1 0 1]
[5 1 1 0 1 0 1]
[3 1 0 1 1 1 0 1]
[0 0 1 1 0 0 0 0 1]
[4 0 0 0 1 0 1 1 1 0]
[4 1 0 1 0 0 1 1 0 0 0]
[1 1 0 1 0 0 1 1 0 0 0 0]
val_acc=0.2109
--------------------------------------------------------------------------------
[5]
[3 0]
[2 0 1]
[5 0 1 1]
[5 1 1 0 1]
[0 1 1 1 1 0]
[5 1 0 1 0 0 1]
[0 1 1 1 0 1 0 1]
[2 1 1 0 0 0 0 0 0]
[1 0 1 0 0 1 0 1 1 0]
[4 1 0 1 1 0 0 1 0 1 0]
[0 1 1 0 0 0 1 1 1 1 0 0]
val_acc=0.1484
--------------------------------------------------------------------------------
Epoch 1: Eval
Eval at 594
valid_eaccuracy: 0.1274
Eval at 594
test_eaccuracy: 0.2133
epoch=1     ch_step=600    loss=-1199.319580 lr=0.0488   |g|=0.2708   tr_acc=18 /128 mins=2.68      
epoch=1     ch_step=650    loss=-1178.380615 lr=0.0488   |g|=0.2675   tr_acc=17 /128 mins=2.75      
epoch=1     ch_step=700    loss=-1240.076538 lr=0.0488   |g|=0.2643   tr_acc=26 /128 mins=2.82      
epoch=1     ch_step=750    loss=-1256.225586 lr=0.0488   |g|=0.2611   tr_acc=24 /128 mins=2.89      
epoch=1     ch_step=800    loss=-1248.874756 lr=0.0488   |g|=0.2579   tr_acc=20 /128 mins=2.96      
epoch=1     ch_step=850    loss=-870.377441 lr=0.0488   |g|=0.2548   tr_acc=20 /128 mins=3.04      
epoch=1     ch_step=900    loss=-1236.123169 lr=0.0488   |g|=0.2517   tr_acc=19 /128 mins=3.11      
epoch=1     ch_step=950    loss=-1237.045044 lr=0.0488   |g|=0.2486   tr_acc=21 /128 mins=3.18      
epoch=1     ch_step=1000   loss=-1297.062988 lr=0.0488   |g|=0.2456   tr_acc=28 /128 mins=3.25      
epoch=1     ch_step=1050   loss=-1299.654175 lr=0.0488   |g|=0.2426   tr_acc=34 /128 mins=3.32      
epoch=1     ch_step=1100   loss=-1249.530151 lr=0.0488   |g|=0.2397   tr_acc=24 /128 mins=3.40      
epoch=1     ch_step=1150   loss=-1279.649170 lr=0.0488   |g|=0.2367   tr_acc=25 /128 mins=3.47      
I0910 14:24:55.661400 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 1188 into outputs/model.ckpt.
W0910 14:24:55.761284 140226417461056 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Epoch 2: Training controller
ctrl_step=50     loss=0.919   ent=26.42 lr=0.0010 |g|=0.0673   acc=0.1406 bl=0.13  mins=3.70
ctrl_step=52     loss=2.064   ent=26.39 lr=0.0010 |g|=0.0912   acc=0.1562 bl=0.13  mins=3.74
ctrl_step=55     loss=-2.005  ent=26.32 lr=0.0010 |g|=0.0259   acc=0.0938 bl=0.13  mins=3.78
ctrl_step=57     loss=2.485   ent=26.48 lr=0.0010 |g|=0.0610   acc=0.1641 bl=0.13  mins=3.82
ctrl_step=60     loss=-2.397  ent=26.40 lr=0.0010 |g|=0.1356   acc=0.0938 bl=0.13  mins=3.86
ctrl_step=62     loss=0.058   ent=26.27 lr=0.0010 |g|=0.0933   acc=0.1328 bl=0.14  mins=3.91
ctrl_step=65     loss=0.297   ent=26.11 lr=0.0010 |g|=0.1095   acc=0.1328 bl=0.13  mins=3.95
ctrl_step=67     loss=-0.557  ent=26.18 lr=0.0010 |g|=0.1028   acc=0.1172 bl=0.13  mins=3.99
ctrl_step=70     loss=-1.750  ent=25.84 lr=0.0010 |g|=0.0345   acc=0.1016 bl=0.13  mins=4.03
ctrl_step=72     loss=0.011   ent=25.79 lr=0.0010 |g|=0.1126   acc=0.1250 bl=0.13  mins=4.08
ctrl_step=75     loss=3.486   ent=25.67 lr=0.0010 |g|=0.2840   acc=0.1797 bl=0.13  mins=4.12
ctrl_step=77     loss=0.391   ent=24.93 lr=0.0010 |g|=0.1592   acc=0.1328 bl=0.13  mins=4.16
ctrl_step=80     loss=4.547   ent=25.65 lr=0.0010 |g|=0.4108   acc=0.1953 bl=0.13  mins=4.20
ctrl_step=82     loss=1.054   ent=24.74 lr=0.0010 |g|=0.0923   acc=0.1484 bl=0.13  mins=4.24
ctrl_step=85     loss=4.288   ent=24.41 lr=0.0010 |g|=0.2095   acc=0.1953 bl=0.13  mins=4.29
ctrl_step=87     loss=-1.021  ent=23.54 lr=0.0010 |g|=0.0921   acc=0.1094 bl=0.13  mins=4.33
ctrl_step=90     loss=0.767   ent=24.44 lr=0.0010 |g|=0.0319   acc=0.1406 bl=0.13  mins=4.37
ctrl_step=92     loss=1.738   ent=24.17 lr=0.0010 |g|=0.0862   acc=0.1562 bl=0.13  mins=4.41
ctrl_step=95     loss=-0.093  ent=23.93 lr=0.0010 |g|=0.0573   acc=0.1250 bl=0.13  mins=4.46
ctrl_step=97     loss=5.093   ent=23.70 lr=0.0010 |g|=0.7586   acc=0.2031 bl=0.13  mins=4.50
Here are 10 architectures
[5]
[5 0]
[1 1 0]
[0 0 0 1]
[4 0 0 0 0]
[0 1 0 0 0 0]
[0 0 1 0 1 1 0]
[2 1 0 0 0 0 0 0]
[5 1 0 0 1 1 0 0 1]
[5 1 0 1 1 0 0 0 1 0]
[5 0 0 0 0 0 0 0 1 1 1]
[0 0 0 0 1 0 0 1 0 0 0 0]
val_acc=0.1562
--------------------------------------------------------------------------------
[4]
[4 0]
[1 1 1]
[1 0 0 0]
[4 1 1 0 0]
[0 0 0 0 0 1]
[5 1 1 0 0 0 1]
[5 1 0 0 0 1 0 1]
[1 0 0 0 1 1 1 0 0]
[4 0 0 0 0 1 1 0 0 0]
[0 0 1 1 0 0 1 1 0 0 1]
[0 0 1 0 1 0 0 1 0 0 0 1]
val_acc=0.1484
--------------------------------------------------------------------------------
[3]
[2 0]
[2 0 0]
[2 1 0 0]
[0 0 0 0 1]
[0 0 0 0 1 1]
[4 0 0 1 1 1 0]
[5 0 0 0 1 0 1 1]
[4 1 0 0 0 0 0 0 0]
[3 0 1 0 0 0 1 1 0 0]
[5 0 0 0 0 0 0 0 1 1 1]
[4 0 0 1 1 0 0 1 0 0 0 0]
val_acc=0.1250
--------------------------------------------------------------------------------
[3]
[5 1]
[3 0 0]
[3 0 1 0]
[3 1 1 0 0]
[2 0 1 0 1 0]
[4 1 1 0 1 0 0]
[1 0 1 1 0 1 0 0]
[3 0 0 0 0 0 0 0 0]
[4 0 0 0 0 0 0 0 0 1]
[0 0 1 0 0 1 1 1 1 1 1]
[2 0 0 0 0 1 0 1 0 0 0 0]
val_acc=0.1719
--------------------------------------------------------------------------------
[2]
[3 0]
[0 0 1]
[1 1 0 0]
[3 0 0 1 0]
[1 1 0 1 0 0]
[3 0 0 0 0 0 0]
[5 0 0 1 1 0 0 1]
[0 1 0 0 0 0 0 0 1]
[1 0 0 1 0 0 1 1 1 1]
[2 0 0 1 1 0 0 0 0 0 0]
[3 0 0 0 1 0 0 1 0 0 0 0]
val_acc=0.1328
--------------------------------------------------------------------------------
[3]
[5 1]
[2 0 0]
[2 0 1 0]
[0 1 1 0 0]
[0 0 1 0 1 0]
[0 1 0 0 0 0 1]
[3 0 0 0 0 0 0 0]
[0 0 1 1 0 1 1 0 0]
[2 1 1 1 0 0 0 0 0 1]
[3 0 0 0 0 0 0 0 0 0 0]
[4 0 0 1 0 1 0 0 1 1 1 1]
val_acc=0.0859
--------------------------------------------------------------------------------
[4]
[1 0]
[2 0 1]
[0 0 0 1]
[5 1 0 0 0]
[0 0 0 0 0 1]
[4 0 0 0 1 1 0]
[1 0 0 0 1 1 0 1]
[5 1 0 1 1 0 0 1 0]
[1 0 0 0 0 0 0 0 0 1]
[2 0 0 0 0 0 0 1 0 0 0]
[5 0 0 1 0 0 1 0 0 1 0 0]
val_acc=0.1328
--------------------------------------------------------------------------------
[0]
[5 1]
[1 0 0]
[5 1 0 0]
[5 1 0 1 0]
[3 0 0 0 1 0]
[2 1 0 0 0 1 0]
[3 0 1 0 0 0 1 1]
[3 0 0 0 0 0 0 0 0]
[1 1 1 0 0 0 0 0 0 0]
[3 0 0 0 0 0 0 0 1 0 1]
[5 1 0 0 0 0 0 0 0 0 1 1]
val_acc=0.0938
--------------------------------------------------------------------------------
[3]
[4 1]
[3 0 0]
[0 0 1 0]
[4 0 0 1 0]
[0 0 0 0 1 0]
[5 1 1 0 0 1 1]
[3 1 0 0 0 0 0 0]
[4 0 0 0 0 1 0 1 0]
[2 1 1 0 1 0 0 0 0 1]
[0 1 1 0 0 1 0 0 0 0 0]
[3 1 1 1 0 0 0 0 0 0 0 0]
val_acc=0.1406
--------------------------------------------------------------------------------
[0]
[5 0]
[1 0 1]
[4 0 0 0]
[0 0 1 0 0]
[5 0 0 1 0 0]
[1 1 0 1 1 0 0]
[0 0 1 0 0 1 1 1]
[0 1 0 0 0 0 0 0 0]
[5 0 1 0 0 0 0 1 0 1]
[0 0 0 0 0 1 1 0 1 0 0]
[2 0 1 0 0 0 0 0 0 0 1 0]
val_acc=0.0859
--------------------------------------------------------------------------------
Epoch 2: Eval
Eval at 1188
valid_eaccuracy: 0.1274
Eval at 1188
test_eaccuracy: 0.2151
epoch=2     ch_step=1200   loss=-1289.494507 lr=0.0453   |g|=0.2339   tr_acc=26 /128 mins=4.69      
epoch=2     ch_step=1250   loss=-1231.492188 lr=0.0453   |g|=0.2313   tr_acc=18 /128 mins=4.76      
epoch=2     ch_step=1300   loss=-1234.836060 lr=0.0453   |g|=0.2287   tr_acc=18 /128 mins=4.83      
epoch=2     ch_step=1350   loss=-1276.952026 lr=0.0453   |g|=0.2261   tr_acc=24 /128 mins=4.90      
epoch=2     ch_step=1400   loss=-1239.904663 lr=0.0453   |g|=0.2235   tr_acc=19 /128 mins=4.98      
epoch=2     ch_step=1450   loss=-1144.385132 lr=0.0453   |g|=0.2210   tr_acc=15 /128 mins=5.05      
epoch=2     ch_step=1500   loss=-1261.817139 lr=0.0453   |g|=0.2185   tr_acc=22 /128 mins=5.12      
epoch=2     ch_step=1550   loss=-1275.731812 lr=0.0453   |g|=0.2161   tr_acc=26 /128 mins=5.19      
epoch=2     ch_step=1600   loss=-1255.302124 lr=0.0453   |g|=0.2136   tr_acc=21 /128 mins=5.27      
epoch=2     ch_step=1650   loss=-1315.768311 lr=0.0453   |g|=0.2112   tr_acc=32 /128 mins=5.34      
epoch=2     ch_step=1700   loss=-1197.040649 lr=0.0453   |g|=0.2088   tr_acc=16 /128 mins=5.41      
epoch=2     ch_step=1750   loss=-1297.062988 lr=0.0453   |g|=0.2065   tr_acc=28 /128 mins=5.48      
I0910 14:26:56.077014 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 1782 into outputs/model.ckpt.
Epoch 3: Training controller
ctrl_step=100    loss=-1.206  ent=22.34 lr=0.0010 |g|=0.1784   acc=0.1094 bl=0.13  mins=5.70
ctrl_step=102    loss=-1.299  ent=23.16 lr=0.0010 |g|=0.0557   acc=0.1094 bl=0.13  mins=5.74
ctrl_step=105    loss=2.043   ent=22.94 lr=0.0010 |g|=0.2322   acc=0.1641 bl=0.13  mins=5.78
ctrl_step=107    loss=0.373   ent=23.38 lr=0.0010 |g|=0.0238   acc=0.1328 bl=0.13  mins=5.82
ctrl_step=110    loss=-3.327  ent=23.97 lr=0.0010 |g|=0.6526   acc=0.0781 bl=0.13  mins=5.86
ctrl_step=112    loss=2.246   ent=22.85 lr=0.0010 |g|=0.1519   acc=0.1641 bl=0.13  mins=5.91
ctrl_step=115    loss=0.699   ent=23.08 lr=0.0010 |g|=0.0857   acc=0.1406 bl=0.13  mins=5.95
ctrl_step=117    loss=-1.839  ent=23.59 lr=0.0010 |g|=0.2985   acc=0.1016 bl=0.13  mins=5.99
ctrl_step=120    loss=-2.068  ent=22.89 lr=0.0010 |g|=0.1268   acc=0.0938 bl=0.13  mins=6.03
ctrl_step=122    loss=-0.585  ent=22.93 lr=0.0010 |g|=0.0304   acc=0.1172 bl=0.13  mins=6.08
ctrl_step=125    loss=-3.947  ent=22.60 lr=0.0010 |g|=0.2662   acc=0.0625 bl=0.13  mins=6.12
ctrl_step=127    loss=-0.226  ent=22.39 lr=0.0010 |g|=0.0149   acc=0.1250 bl=0.13  mins=6.16
ctrl_step=130    loss=0.765   ent=21.91 lr=0.0010 |g|=0.1111   acc=0.1406 bl=0.13  mins=6.20
ctrl_step=132    loss=1.193   ent=22.40 lr=0.0010 |g|=0.0739   acc=0.1484 bl=0.13  mins=6.24
ctrl_step=135    loss=7.378   ent=22.57 lr=0.0010 |g|=0.6751   acc=0.2422 bl=0.13  mins=6.29
ctrl_step=137    loss=-2.935  ent=22.58 lr=0.0010 |g|=0.1821   acc=0.0781 bl=0.13  mins=6.33
ctrl_step=140    loss=-0.858  ent=22.17 lr=0.0010 |g|=0.1787   acc=0.1094 bl=0.13  mins=6.37
ctrl_step=142    loss=-2.076  ent=22.63 lr=0.0010 |g|=0.1741   acc=0.0938 bl=0.13  mins=6.41
ctrl_step=145    loss=-1.580  ent=22.76 lr=0.0010 |g|=0.1273   acc=0.1016 bl=0.13  mins=6.45
ctrl_step=147    loss=-2.988  ent=22.36 lr=0.0010 |g|=0.6083   acc=0.0781 bl=0.13  mins=6.49
Here are 10 architectures
[0]
[0 0]
[5 0 1]
[3 0 0 0]
[5 0 1 0 0]
[3 0 0 0 1 0]
[2 0 0 0 1 0 0]
[2 0 0 0 0 1 1 1]
[0 0 0 0 1 0 1 0 0]
[5 1 1 1 1 1 1 0 0 1]
[2 1 0 0 1 0 0 0 1 0 0]
[0 0 1 1 0 0 0 0 0 0 1 0]
val_acc=0.1250
--------------------------------------------------------------------------------
[5]
[3 0]
[5 0 0]
[1 0 1 0]
[2 1 0 1 0]
[2 1 0 0 1 1]
[4 1 0 0 1 0 1]
[3 0 0 0 1 0 0 0]
[0 0 0 1 0 0 0 0 1]
[2 1 1 0 1 0 1 0 0 0]
[1 0 0 1 0 0 0 0 1 1 0]
[1 0 0 1 0 1 1 1 0 0 1 0]
val_acc=0.1719
--------------------------------------------------------------------------------
[2]
[1 0]
[4 1 0]
[0 0 1 0]
[3 1 0 0 0]
[1 1 0 0 0 0]
[5 0 0 0 0 0 0]
[3 1 0 0 0 0 1 0]
[4 0 0 1 0 1 0 0 1]
[1 0 0 0 1 0 0 0 0 0]
[5 0 0 1 0 1 1 1 0 0 0]
[2 0 1 0 0 0 0 0 0 1 0 1]
val_acc=0.1094
--------------------------------------------------------------------------------
[2]
[3 0]
[1 1 0]
[1 0 0 0]
[1 0 0 0 0]
[3 0 0 1 0 0]
[2 0 1 0 0 0 1]
[4 0 0 0 0 0 0 1]
[3 1 0 0 0 1 1 0 1]
[5 1 0 0 0 0 0 1 0 0]
[4 1 0 0 0 0 0 0 1 0 0]
[3 0 1 0 1 0 1 0 0 0 0 0]
val_acc=0.0859
--------------------------------------------------------------------------------
[3]
[5 1]
[5 0 0]
[2 0 1 1]
[1 0 1 0 1]
[1 1 0 0 0 0]
[5 1 1 0 0 1 1]
[0 0 0 0 0 0 1 0]
[0 0 0 0 1 1 0 1 1]
[5 0 0 0 0 0 1 1 1 0]
[5 0 0 0 1 0 0 0 0 1 0]
[4 0 0 0 0 0 0 0 0 1 0 0]
val_acc=0.1562
--------------------------------------------------------------------------------
[3]
[0 1]
[2 1 0]
[3 0 1 1]
[1 0 1 0 1]
[1 1 1 0 0 1]
[5 1 1 0 1 1 0]
[4 0 0 0 0 0 0 0]
[3 0 0 0 1 0 1 0 0]
[4 0 1 0 0 0 1 0 0 0]
[0 0 0 1 1 0 0 0 1 1 0]
[5 0 0 0 0 0 0 0 0 0 1 0]
val_acc=0.1094
--------------------------------------------------------------------------------
[2]
[2 1]
[1 0 1]
[4 1 0 0]
[3 1 1 1 0]
[2 0 1 1 0 0]
[3 0 0 1 0 0 1]
[0 0 0 0 1 1 1 0]
[2 0 1 0 0 1 0 0 0]
[1 1 0 0 1 0 0 0 0 0]
[3 0 0 0 0 1 0 0 1 0 0]
[0 1 0 0 1 1 0 0 0 0 0 0]
val_acc=0.1016
--------------------------------------------------------------------------------
[5]
[0 0]
[5 1 1]
[2 0 0 1]
[5 0 1 1 0]
[0 1 1 1 1 1]
[3 0 1 0 0 0 1]
[0 1 0 1 0 0 1 1]
[5 1 0 0 0 0 1 1 1]
[3 0 0 1 0 0 1 1 1 1]
[4 0 0 1 0 0 1 0 0 1 0]
[1 1 0 0 0 0 0 0 1 0 1 0]
val_acc=0.1172
--------------------------------------------------------------------------------
[5]
[2 1]
[4 1 1]
[4 1 0 1]
[5 1 1 1 0]
[3 0 0 0 0 0]
[4 0 0 1 0 0 0]
[5 0 0 1 0 0 0 0]
[1 0 0 1 1 0 0 0 1]
[4 1 0 0 0 0 0 0 0 0]
[5 1 1 0 0 0 0 0 0 0 0]
[1 1 0 0 0 1 0 0 1 1 0 0]
val_acc=0.1016
--------------------------------------------------------------------------------
[4]
[0 0]
[5 0 0]
[4 1 1 0]
[5 0 0 1 0]
[3 1 1 1 0 1]
[1 0 0 1 0 1 0]
[3 0 1 0 0 1 1 1]
[4 0 0 0 0 1 0 0 0]
[4 1 1 1 0 0 0 0 1 0]
[2 1 0 0 1 0 0 0 1 1 1]
[5 0 0 0 0 1 1 0 1 1 0 0]
val_acc=0.1484
--------------------------------------------------------------------------------
Epoch 3: Eval
Eval at 1782
valid_eaccuracy: 0.1274
Eval at 1782
test_eaccuracy: 0.2168
epoch=3     ch_step=1800   loss=-1269.474365 lr=0.0398   |g|=0.2043   tr_acc=23 /128 mins=6.69      
epoch=3     ch_step=1850   loss=-1237.044922 lr=0.0398   |g|=0.2022   tr_acc=21 /128 mins=6.76      
epoch=3     ch_step=1900   loss=-1269.474365 lr=0.0398   |g|=0.2002   tr_acc=23 /128 mins=6.83      
epoch=3     ch_step=1950   loss=-854.259277 lr=0.0398   |g|=0.1982   tr_acc=22 /128 mins=6.91      
epoch=3     ch_step=2000   loss=-1279.649170 lr=0.0398   |g|=0.1963   tr_acc=25 /128 mins=6.98      
epoch=3     ch_step=2050   loss=-1297.468750 lr=0.0398   |g|=0.1943   tr_acc=27 /128 mins=7.05      
epoch=3     ch_step=2100   loss=-1238.135742 lr=0.0398   |g|=0.1924   tr_acc=20 /128 mins=7.12      
epoch=3     ch_step=2150   loss=-1229.385254 lr=0.0398   |g|=0.1905   tr_acc=22 /128 mins=7.19      
epoch=3     ch_step=2200   loss=-1326.163086 lr=0.0398   |g|=0.1886   tr_acc=31 /128 mins=7.27      
epoch=3     ch_step=2250   loss=-1317.079102 lr=0.0398   |g|=0.1867   tr_acc=30 /128 mins=7.34      
epoch=3     ch_step=2300   loss=-1252.867554 lr=0.0398   |g|=0.1849   tr_acc=22 /128 mins=7.41      
epoch=3     ch_step=2350   loss=-1153.044678 lr=0.0398   |g|=0.1830   tr_acc=12 /128 mins=7.48      
I0910 14:28:55.491475 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 2376 into outputs/model.ckpt.
Epoch 4: Training controller
ctrl_step=150    loss=0.757   ent=23.32 lr=0.0010 |g|=0.0259   acc=0.1406 bl=0.13  mins=7.69
ctrl_step=152    loss=1.180   ent=23.36 lr=0.0010 |g|=0.0563   acc=0.1484 bl=0.13  mins=7.73
ctrl_step=155    loss=-0.828  ent=21.90 lr=0.0010 |g|=0.1500   acc=0.1172 bl=0.13  mins=7.77
ctrl_step=157    loss=0.617   ent=22.51 lr=0.0010 |g|=0.0834   acc=0.1406 bl=0.13  mins=7.81
ctrl_step=160    loss=1.516   ent=22.29 lr=0.0010 |g|=0.2537   acc=0.1562 bl=0.13  mins=7.86
ctrl_step=162    loss=-1.840  ent=22.71 lr=0.0010 |g|=0.1447   acc=0.1016 bl=0.13  mins=7.90
ctrl_step=165    loss=-0.666  ent=21.99 lr=0.0010 |g|=0.0947   acc=0.1172 bl=0.13  mins=7.94
ctrl_step=167    loss=-1.376  ent=22.45 lr=0.0010 |g|=0.0759   acc=0.1094 bl=0.13  mins=7.98
ctrl_step=170    loss=0.274   ent=22.86 lr=0.0010 |g|=0.0225   acc=0.1328 bl=0.13  mins=8.02
ctrl_step=172    loss=-2.620  ent=23.19 lr=0.0010 |g|=0.2517   acc=0.0859 bl=0.13  mins=8.07
ctrl_step=175    loss=1.306   ent=22.70 lr=0.0010 |g|=0.0758   acc=0.1484 bl=0.13  mins=8.11
ctrl_step=177    loss=-1.348  ent=23.27 lr=0.0010 |g|=0.1958   acc=0.1094 bl=0.13  mins=8.15
ctrl_step=180    loss=0.694   ent=22.67 lr=0.0010 |g|=0.0492   acc=0.1406 bl=0.13  mins=8.19
ctrl_step=182    loss=-0.551  ent=22.49 lr=0.0010 |g|=0.0374   acc=0.1172 bl=0.13  mins=8.24
ctrl_step=185    loss=-3.626  ent=22.32 lr=0.0010 |g|=0.1527   acc=0.0703 bl=0.13  mins=8.28
ctrl_step=187    loss=3.655   ent=22.30 lr=0.0010 |g|=0.1852   acc=0.1875 bl=0.13  mins=8.32
ctrl_step=190    loss=-0.682  ent=22.81 lr=0.0010 |g|=0.0385   acc=0.1172 bl=0.13  mins=8.36
ctrl_step=192    loss=0.325   ent=21.41 lr=0.0010 |g|=0.0169   acc=0.1328 bl=0.13  mins=8.40
ctrl_step=195    loss=0.075   ent=22.57 lr=0.0010 |g|=0.0189   acc=0.1250 bl=0.13  mins=8.44
ctrl_step=197    loss=-1.492  ent=22.41 lr=0.0010 |g|=0.1038   acc=0.1016 bl=0.13  mins=8.49
Here are 10 architectures
[3]
[0 0]
[2 0 0]
[3 1 0 1]
[1 0 1 1 1]
[1 1 0 0 0 0]
[0 1 1 1 0 1 0]
[3 0 0 0 1 0 0 0]
[4 1 1 0 0 0 0 0 0]
[3 0 0 1 1 0 0 1 0 0]
[1 1 0 0 0 0 0 0 0 0 0]
[4 0 0 0 1 0 0 1 0 1 1 0]
val_acc=0.1094
--------------------------------------------------------------------------------
[0]
[0 1]
[0 0 1]
[4 1 0 1]
[0 1 1 1 0]
[2 1 0 0 1 1]
[1 0 0 1 0 0 0]
[3 0 0 1 0 1 1 1]
[5 0 0 0 1 0 0 0 0]
[3 0 0 1 0 0 1 0 0 1]
[2 1 0 0 0 0 0 1 0 0 0]
[4 1 0 1 0 0 0 0 1 1 1 0]
val_acc=0.0938
--------------------------------------------------------------------------------
[1]
[5 0]
[3 0 0]
[1 0 1 0]
[2 0 1 0 0]
[3 1 1 0 0 0]
[3 1 1 1 0 1 1]
[5 0 1 1 1 0 0 0]
[1 1 0 0 0 0 0 1 0]
[1 1 0 0 0 0 0 0 0 0]
[1 1 1 1 1 0 0 0 0 0 1]
[3 1 0 0 0 0 0 0 0 0 0 0]
val_acc=0.1875
--------------------------------------------------------------------------------
[2]
[4 0]
[4 1 0]
[4 0 0 0]
[1 0 1 0 0]
[0 0 0 1 1 0]
[4 0 0 0 1 0 1]
[5 1 0 0 1 1 0 0]
[0 0 0 1 1 1 1 0 1]
[0 0 0 0 1 1 0 0 0 0]
[5 0 0 0 0 0 0 1 1 0 0]
[2 0 0 0 0 1 0 0 1 0 1 1]
val_acc=0.1406
--------------------------------------------------------------------------------
[3]
[2 0]
[1 1 0]
[2 1 1 1]
[5 1 1 1 0]
[4 0 0 1 1 0]
[5 0 0 0 0 0 0]
[1 1 0 1 0 1 0 1]
[1 0 1 0 1 0 1 0 0]
[3 0 0 1 0 1 0 0 0 0]
[4 1 0 0 0 0 0 1 1 1 0]
[2 0 0 0 0 1 0 1 0 0 1 1]
val_acc=0.1406
--------------------------------------------------------------------------------
[1]
[3 1]
[5 1 0]
[2 0 1 1]
[1 1 1 0 0]
[5 1 0 0 0 0]
[0 0 0 0 1 1 0]
[1 0 0 0 1 1 0 0]
[1 0 1 0 1 1 1 0 0]
[1 0 0 0 0 0 1 0 0 0]
[3 0 1 1 0 1 0 0 0 0 0]
[5 0 0 0 0 1 0 0 0 0 0 1]
val_acc=0.1250
--------------------------------------------------------------------------------
[2]
[5 0]
[2 1 1]
[2 0 0 0]
[4 0 0 0 0]
[3 0 0 0 0 0]
[0 0 0 0 0 0 0]
[5 0 1 1 0 0 0 1]
[0 0 0 1 1 0 0 1 1]
[2 1 0 0 0 0 0 1 0 0]
[4 1 0 0 1 1 0 0 0 0 0]
[2 1 0 0 0 0 0 0 0 0 0 0]
val_acc=0.1094
--------------------------------------------------------------------------------
[2]
[1 0]
[0 1 0]
[2 0 0 0]
[5 0 0 1 1]
[3 1 0 0 1 1]
[0 0 0 0 0 1 0]
[1 0 0 1 0 0 0 0]
[4 0 1 0 0 1 0 1 1]
[3 0 0 0 1 0 0 0 0 0]
[1 0 1 0 1 0 0 0 0 1 1]
[3 0 0 1 0 0 0 1 0 0 0 0]
val_acc=0.1641
--------------------------------------------------------------------------------
[1]
[0 1]
[4 0 0]
[5 0 0 1]
[2 0 0 0 0]
[3 1 0 0 1 0]
[5 0 0 0 0 0 0]
[3 0 1 0 1 1 0 0]
[0 0 1 0 0 1 0 0 0]
[2 0 1 1 0 0 0 0 1 1]
[4 0 0 1 0 1 0 0 0 1 0]
[4 0 0 0 1 1 0 0 0 1 1 0]
val_acc=0.1797
--------------------------------------------------------------------------------
[4]
[2 0]
[4 0 0]
[3 0 1 0]
[3 0 0 1 0]
[1 0 0 0 0 0]
[1 0 0 0 0 0 0]
[3 0 0 0 0 0 0 0]
[0 1 0 1 0 0 0 0 0]
[4 0 0 0 0 0 0 0 0 0]
[5 0 0 0 1 1 0 1 0 0 1]
[1 1 0 1 0 1 1 1 0 0 1 0]
val_acc=0.1562
--------------------------------------------------------------------------------
Epoch 4: Eval
Eval at 2376
valid_eaccuracy: 0.1274
Eval at 2376
test_eaccuracy: 0.2168
epoch=4     ch_step=2400   loss=-1232.189087 lr=0.0329   |g|=0.1814   tr_acc=18 /128 mins=8.69      
epoch=4     ch_step=2450   loss=-1245.594482 lr=0.0329   |g|=0.1799   tr_acc=24 /128 mins=8.77      
epoch=4     ch_step=2500   loss=-757.550659 lr=0.0329   |g|=0.1784   tr_acc=34 /128 mins=8.84      
epoch=4     ch_step=2550   loss=-1230.169434 lr=0.0329   |g|=0.1769   tr_acc=22 /128 mins=8.91      
epoch=4     ch_step=2600   loss=-1230.169434 lr=0.0329   |g|=0.1755   tr_acc=22 /128 mins=8.98      
epoch=4     ch_step=2650   loss=-1246.515503 lr=0.0329   |g|=0.1741   tr_acc=20 /128 mins=9.05      
epoch=4     ch_step=2700   loss=-1226.407959 lr=0.0329   |g|=0.1726   tr_acc=21 /128 mins=9.13      
epoch=4     ch_step=2750   loss=-1236.407715 lr=0.0329   |g|=0.1712   tr_acc=22 /128 mins=9.20      
epoch=4     ch_step=2800   loss=-1213.943481 lr=0.0329   |g|=0.1698   tr_acc=15 /128 mins=9.27      
epoch=4     ch_step=2850   loss=-1208.857422 lr=0.0329   |g|=0.1684   tr_acc=23 /128 mins=9.34      
epoch=4     ch_step=2900   loss=-1294.157837 lr=0.0329   |g|=0.1670   tr_acc=27 /128 mins=9.42      
epoch=4     ch_step=2950   loss=-1176.621338 lr=0.0329   |g|=0.1657   tr_acc=19 /128 mins=9.49      
I0910 14:30:55.403214 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 2970 into outputs/model.ckpt.
Epoch 5: Training controller
ctrl_step=200    loss=0.827   ent=23.39 lr=0.0010 |g|=0.0324   acc=0.1406 bl=0.13  mins=9.69
ctrl_step=202    loss=-2.842  ent=23.59 lr=0.0010 |g|=0.4320   acc=0.0859 bl=0.13  mins=9.73
ctrl_step=205    loss=1.289   ent=23.04 lr=0.0010 |g|=0.0654   acc=0.1484 bl=0.13  mins=9.77
ctrl_step=207    loss=0.210   ent=22.95 lr=0.0010 |g|=0.0247   acc=0.1328 bl=0.13  mins=9.81
ctrl_step=210    loss=0.778   ent=22.56 lr=0.0010 |g|=0.0722   acc=0.1406 bl=0.13  mins=9.86
ctrl_step=212    loss=-1.021  ent=22.51 lr=0.0010 |g|=0.0506   acc=0.1094 bl=0.13  mins=9.90
ctrl_step=215    loss=-2.428  ent=22.55 lr=0.0010 |g|=0.1291   acc=0.0859 bl=0.13  mins=9.94
ctrl_step=217    loss=-3.244  ent=23.25 lr=0.0010 |g|=0.2116   acc=0.0781 bl=0.13  mins=9.98
ctrl_step=220    loss=0.282   ent=23.90 lr=0.0010 |g|=0.0228   acc=0.1328 bl=0.13  mins=10.03
ctrl_step=222    loss=1.962   ent=23.54 lr=0.0010 |g|=0.0957   acc=0.1562 bl=0.13  mins=10.07
ctrl_step=225    loss=-1.115  ent=23.30 lr=0.0010 |g|=0.0498   acc=0.1094 bl=0.13  mins=10.11
ctrl_step=227    loss=0.263   ent=23.07 lr=0.0010 |g|=0.0405   acc=0.1328 bl=0.13  mins=10.15
ctrl_step=230    loss=2.557   ent=23.11 lr=0.0010 |g|=0.0831   acc=0.1719 bl=0.13  mins=10.19
ctrl_step=232    loss=-2.702  ent=22.48 lr=0.0010 |g|=0.2706   acc=0.0859 bl=0.13  mins=10.23
ctrl_step=235    loss=1.699   ent=22.88 lr=0.0010 |g|=0.0745   acc=0.1562 bl=0.13  mins=10.28
ctrl_step=237    loss=-0.777  ent=22.11 lr=0.0010 |g|=0.0826   acc=0.1172 bl=0.13  mins=10.32
ctrl_step=240    loss=-1.177  ent=22.61 lr=0.0010 |g|=0.0537   acc=0.1094 bl=0.13  mins=10.36
ctrl_step=242    loss=-4.860  ent=23.21 lr=0.0010 |g|=0.6427   acc=0.0547 bl=0.13  mins=10.40
ctrl_step=245    loss=2.824   ent=22.25 lr=0.0010 |g|=0.1201   acc=0.1719 bl=0.13  mins=10.44
ctrl_step=247    loss=-0.028  ent=23.15 lr=0.0010 |g|=0.0127   acc=0.1250 bl=0.13  mins=10.48
Here are 10 architectures
[2]
[4 0]
[0 0 1]
[0 0 0 0]
[1 1 0 1 0]
[4 0 1 1 1 0]
[1 1 0 1 1 0 1]
[3 0 0 1 0 1 0 1]
[1 0 0 0 0 0 1 0 0]
[4 1 0 1 0 0 0 0 0 0]
[2 0 1 0 0 0 1 0 1 1 0]
[5 0 0 1 0 0 0 0 1 1 1 1]
val_acc=0.1328
--------------------------------------------------------------------------------
[3]
[0 0]
[5 1 1]
[1 1 1 1]
[4 1 0 0 1]
[1 1 0 1 0 1]
[1 1 0 0 1 0 0]
[4 0 0 0 0 0 0 0]
[3 0 0 0 0 0 0 0 0]
[0 0 0 0 1 1 0 0 1 1]
[3 0 0 1 1 1 1 0 0 0 0]
[5 0 1 1 1 1 0 0 1 0 0 1]
val_acc=0.0938
--------------------------------------------------------------------------------
[1]
[4 0]
[0 0 0]
[0 1 1 0]
[4 0 0 1 0]
[5 0 1 0 1 0]
[4 0 0 0 1 0 1]
[2 1 1 0 0 0 0 1]
[1 0 0 1 0 0 0 0 1]
[1 0 0 1 1 1 0 0 0 1]
[3 0 0 0 0 0 0 0 0 0 0]
[3 1 0 1 0 0 1 1 0 0 0 0]
val_acc=0.1172
--------------------------------------------------------------------------------
[0]
[1 0]
[2 0 0]
[2 0 0 0]
[1 0 0 0 0]
[1 0 1 1 0 0]
[4 0 1 0 0 0 0]
[1 0 1 1 0 0 0 0]
[5 1 0 1 0 0 0 0 0]
[4 0 0 0 0 0 0 0 0 0]
[0 0 1 0 1 1 0 0 0 0 1]
[2 1 0 0 0 0 0 0 0 0 0 1]
val_acc=0.0781
--------------------------------------------------------------------------------
[4]
[1 0]
[0 1 1]
[4 1 0 1]
[0 0 1 0 0]
[2 0 0 1 0 1]
[3 1 0 0 0 0 0]
[0 1 1 0 1 0 1 0]
[4 1 0 1 1 0 0 0 0]
[0 0 0 1 1 1 0 0 0 1]
[3 0 0 1 0 0 1 1 0 1 1]
[4 0 0 1 0 0 0 1 0 0 0 1]
val_acc=0.1953
--------------------------------------------------------------------------------
[1]
[3 1]
[5 0 0]
[5 1 0 1]
[0 0 0 1 0]
[5 1 1 0 1 0]
[0 0 0 0 1 0 1]
[3 0 0 1 0 0 0 1]
[2 0 1 0 0 0 0 1 0]
[2 0 0 0 0 0 0 1 1 0]
[3 0 0 0 0 0 0 1 0 0 1]
[4 0 1 1 1 0 0 0 1 0 1 0]
val_acc=0.0781
--------------------------------------------------------------------------------
[1]
[5 0]
[3 0 0]
[1 0 1 0]
[3 0 1 0 0]
[2 0 0 0 0 0]
[4 0 0 1 1 1 0]
[1 1 0 1 0 0 0 0]
[1 0 1 0 0 1 0 0 1]
[3 0 0 0 0 1 1 1 1 0]
[5 1 0 0 0 0 0 0 0 0 1]
[5 0 1 0 0 0 0 0 0 0 0 0]
val_acc=0.1016
--------------------------------------------------------------------------------
[5]
[1 0]
[3 1 0]
[2 1 1 0]
[0 0 1 0 0]
[2 0 0 0 1 1]
[5 1 1 1 0 0 0]
[3 1 0 0 1 1 0 0]
[5 1 1 0 1 0 0 0 1]
[1 0 1 0 0 1 1 1 0 1]
[1 1 0 0 0 1 1 0 0 0 0]
[0 1 0 1 0 0 0 0 0 0 0 0]
val_acc=0.1719
--------------------------------------------------------------------------------
[3]
[3 1]
[1 1 0]
[4 0 1 0]
[3 0 1 0 1]
[5 0 0 0 1 0]
[3 0 0 0 0 0 0]
[5 0 0 1 0 0 0 1]
[5 1 0 1 0 0 1 0 1]
[0 1 1 0 1 0 1 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0]
[2 1 1 0 0 0 0 0 0 0 1 0]
val_acc=0.1562
--------------------------------------------------------------------------------
[3]
[2 0]
[1 0 1]
[4 0 0 0]
[4 0 1 0 1]
[4 1 1 0 0 0]
[0 0 0 0 1 0 0]
[2 0 0 0 0 0 0 1]
[4 1 0 1 1 0 1 0 0]
[0 0 0 1 1 1 0 1 0 0]
[4 0 0 0 0 0 0 0 1 1 0]
[3 0 1 0 0 0 0 0 0 1 0 1]
val_acc=0.0703
--------------------------------------------------------------------------------
Epoch 5: Eval
Eval at 2970
valid_eaccuracy: 0.1274
Eval at 2970
test_eaccuracy: 0.2162
epoch=5     ch_step=3000   loss=-1272.391724 lr=0.0253   |g|=0.1645   tr_acc=24 /128 mins=10.70     
epoch=5     ch_step=3050   loss=-1236.374634 lr=0.0253   |g|=0.1635   tr_acc=19 /128 mins=10.77     
epoch=5     ch_step=3100   loss=-1207.006104 lr=0.0253   |g|=0.1624   tr_acc=17 /128 mins=10.84     
epoch=5     ch_step=3150   loss=-1239.481445 lr=0.0253   |g|=0.1614   tr_acc=23 /128 mins=10.91     
epoch=5     ch_step=3200   loss=-1262.386230 lr=0.0253   |g|=0.1604   tr_acc=24 /128 mins=10.98     
epoch=5     ch_step=3250   loss=-1261.816895 lr=0.0253   |g|=0.1594   tr_acc=22 /128 mins=11.06     
epoch=5     ch_step=3300   loss=-1255.706055 lr=0.0253   |g|=0.1584   tr_acc=21 /128 mins=11.13     
epoch=5     ch_step=3350   loss=-1208.857422 lr=0.0253   |g|=0.1574   tr_acc=23 /128 mins=11.20     
epoch=5     ch_step=3400   loss=-1283.646484 lr=0.0253   |g|=0.1564   tr_acc=25 /128 mins=11.27     
epoch=5     ch_step=3450   loss=-1249.927734 lr=0.0253   |g|=0.1554   tr_acc=21 /128 mins=11.34     
epoch=5     ch_step=3500   loss=-1245.212891 lr=0.0253   |g|=0.1544   tr_acc=25 /128 mins=11.41     
epoch=5     ch_step=3550   loss=-1220.797363 lr=0.0253   |g|=0.1534   tr_acc=16 /128 mins=11.48     
I0910 14:32:54.612292 140226417461056 basic_session_run_hooks.py:606] Saving checkpoints for 3564 into outputs/model.ckpt.
Epoch 6: Training controller
ctrl_step=250    loss=-1.582  ent=22.79 lr=0.0010 |g|=0.0713   acc=0.1016 bl=0.13  mins=11.67
ctrl_step=252    loss=0.404   ent=23.41 lr=0.0010 |g|=0.0505   acc=0.1328 bl=0.13  mins=11.71
