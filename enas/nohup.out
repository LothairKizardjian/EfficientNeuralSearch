2019-09-03 13:37:43.922382: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-03 13:37:44.026403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-03 13:37:44.512115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3ba1240 executing computations on platform CUDA. Devices:
2019-09-03 13:37:44.512183: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-03 13:37:44.637117: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-03 13:37:44.638428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x387ded0 executing computations on platform Host. Devices:
2019-09-03 13:37:44.638480: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-03 13:37:44.640383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-03 13:37:44.640891: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 13:37:44.643572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 13:37:44.717560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 13:37:44.742392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 13:37:44.744944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 13:37:44.788411: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 13:37:44.794133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-03 13:37:44.796687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-03 13:37:44.814418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 13:37:44.839208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-03 13:37:44.839247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-03 13:37:44.839261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-03 13:37:44.853701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0903 13:37:44.856098 139848493078336 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 12282960815992332222
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 9385906680094336226
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 562436015309401265
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 283371775182670676
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading games for pgn chess_games_2000 ...
3000 games loaded
loading tensors and according labels ...
Loading data for chess_games_2001
Loading games for pgn chess_games_2001 ...
3000 games loaded
loading tensors and according labels ...
Loading data for chess_games_2002
Loading games for pgn chess_games_2002 ...
3000 games loaded
loading tensors and according labels ...
Loading data for chess_games_2003
Loading games for pgn chess_games_2003 ...
3000 games loaded
loading tensors and according labels ...
Loading data for chess_games_2004
Loading games for pgn chess_games_2004 ...
3000 games loaded
loading tensors and according labels ...
Loading data ...
Loading data for chess_games_2005
Loading games for pgn chess_games_2005 ...
3000 games loaded
loading tensors and according labels ...
--------------------------------------------------------------------------------
Build model child
Build data ops
W0903 13:50:49.142526 139848493078336 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
Traceback (most recent call last):
  File "src/chess/main.py", line 395, in <module>
    tf.app.run()
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "src/chess/main.py", line 384, in main
    train()
  File "src/chess/main.py", line 235, in train
    ops = get_ops(images, labels)
  File "src/chess/main.py", line 150, in get_ops
    num_replicas=FLAGS.child_num_replicas,
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py", line 80, in __init__
    name=name,
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py", line 83, in __init__
    allow_smaller_final_batch=True,
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 324, in new_func
    return func(*args, **kwargs)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 1348, in shuffle_batch
    name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 852, in _shuffle_batch
    tensor_list = _validate(tensor_list)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 632, in _validate
    tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1456, in convert_n_to_tensor_or_indexed_slices
    values=values, dtype=dtype, name=name, as_ref=False)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1428, in internal_convert_n_to_tensor_or_indexed_slices
    value, dtype=dtype, name=n, as_ref=as_ref))
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1388, in internal_convert_to_tensor_or_indexed_slices
    value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
    allow_broadcast=True)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 537, in make_tensor_proto
    "Cannot create a tensor proto whose content is larger than 2GB.")
ValueError: Cannot create a tensor proto whose content is larger than 2GB.
Exception ignored in: <src.utils.Logger object at 0x7f309e97ff98>
AttributeError: 'Logger' object has no attribute 'flush'
Traceback (most recent call last):
  File "src/chess/main.py", line 16, in <module>
    from src.chess.data_utils import read_data
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 3, in <module>
    import _pickle as pickle
ImportError: No module named _pickle
2019-09-03 14:05:07.868512: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-03 14:05:07.904419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-03 14:05:08.155700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f6d120 executing computations on platform CUDA. Devices:
2019-09-03 14:05:08.155754: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-03 14:05:08.177151: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-03 14:05:08.178651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3c49890 executing computations on platform Host. Devices:
2019-09-03 14:05:08.178697: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-03 14:05:08.180480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-03 14:05:08.180973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 14:05:08.183717: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 14:05:08.185994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 14:05:08.186548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 14:05:08.189738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 14:05:08.192179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 14:05:08.199028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-03 14:05:08.201534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-03 14:05:08.201594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 14:05:08.203288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-03 14:05:08.203315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-03 14:05:08.203327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-03 14:05:08.206169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0903 14:05:08.207548 139693522106176 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 8918955427269983331
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 18406153764589738692
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 10433701835836523769
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 17841746793393069757
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0903 14:05:22.040605 139693522106176 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
Traceback (most recent call last):
  File "src/chess/main.py", line 395, in <module>
    tf.app.run()
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "src/chess/main.py", line 384, in main
    train()
  File "src/chess/main.py", line 235, in train
    ops = get_ops(images, labels)
  File "src/chess/main.py", line 150, in get_ops
    num_replicas=FLAGS.child_num_replicas,
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py", line 80, in __init__
    name=name,
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py", line 83, in __init__
    allow_smaller_final_batch=True,
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 324, in new_func
    return func(*args, **kwargs)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 1348, in shuffle_batch
    name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 852, in _shuffle_batch
    tensor_list = _validate(tensor_list)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py", line 632, in _validate
    tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1456, in convert_n_to_tensor_or_indexed_slices
    values=values, dtype=dtype, name=name, as_ref=False)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1428, in internal_convert_n_to_tensor_or_indexed_slices
    value, dtype=dtype, name=n, as_ref=as_ref))
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1388, in internal_convert_to_tensor_or_indexed_slices
    value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
    allow_broadcast=True)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 537, in make_tensor_proto
    "Cannot create a tensor proto whose content is larger than 2GB.")
ValueError: Cannot create a tensor proto whose content is larger than 2GB.
Exception ignored in: <src.utils.Logger object at 0x7f0c899b6f28>
AttributeError: 'Logger' object has no attribute 'flush'
Traceback (most recent call last):
  File "src/chess/main.py", line 16, in <module>
    from src.chess.data_utils import read_data
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 42
    print board.shape
              ^
SyntaxError: Missing parentheses in call to 'print'. Did you mean print(board.shape)?
2019-09-09 14:26:03.750240: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:26:03.872415: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:26:04.230614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d25510 executing computations on platform CUDA. Devices:
2019-09-09 14:26:04.230695: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:26:04.353073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:26:04.354497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a02330 executing computations on platform Host. Devices:
2019-09-09 14:26:04.354556: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:26:04.356408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:26:04.356895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:26:04.359470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:26:04.361622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:26:04.362188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:26:04.365268: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:26:04.367143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:26:04.389170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:26:04.391727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:26:04.402229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:26:04.403953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:26:04.403983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:26:04.403996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:26:04.408408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:26:04.413792 140355173271360 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 13649272611742642674
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17067699738207810501
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 11076572809616299191
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 6843572898606758058
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading games for pgn chess_games_2003 ...
500 games loaded
loading tensors and according labels ...
Loading data for chess_games_2004
Loading games for pgn chess_games_2004 ...
500 games loaded
loading tensors and according labels ...
Loading data ...
Loading data for chess_games_2005
Loading games for pgn chess_games_2005 ...
500 games loaded
loading tensors and according labels ...
Traceback (most recent call last):
  File "src/chess/main.py", line 395, in <module>
    tf.app.run()
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "src/chess/main.py", line 384, in main
    train()
  File "src/chess/main.py", line 229, in train
    images, labels = read_data(FLAGS.data_path)
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 42, in read_data
    print(boards.shape)
AttributeError: 'dict' object has no attribute 'shape'
Exception ignored in: <src.utils.Logger object at 0x7fa697161f60>
AttributeError: 'Logger' object has no attribute 'flush'
2019-09-09 14:27:56.345008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:27:56.379116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:27:56.627131: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x37de570 executing computations on platform CUDA. Devices:
2019-09-09 14:27:56.627192: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:27:56.649106: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:27:56.650793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x34bb9f0 executing computations on platform Host. Devices:
2019-09-09 14:27:56.650834: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:27:56.652413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:27:56.652848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:27:56.655344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:27:56.657412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:27:56.657944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:27:56.660953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:27:56.663217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:27:56.669105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:27:56.672339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:27:56.672403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:27:56.674650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:27:56.674684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:27:56.674696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:27:56.677540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:27:56.678863 139966734747456 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 3460430718220410166
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 18064999096584212642
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 8789457796126723574
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 5714893761442860190
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0909 14:27:58.631989 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0909 14:28:01.388742 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:28:01.390736 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:28:01.457969 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0909 14:28:01.854372 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0909 14:28:02.390537 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0909 14:28:02.391268 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0909 14:28:02.499174 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0909 14:28:02.596472 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0909 14:28:07.630459 139966734747456 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0909 14:28:07.662770 139966734747456 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0909 14:28:07.685902 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0909 14:28:07.874567 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0909 14:28:08.111939 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-09 14:28:09.199857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:28:09.199970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:28:09.199994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:28:09.200013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:28:09.200031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:28:09.200048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:28:09.200076: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:28:09.200100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:28:09.202484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:28:09.202559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:28:09.202574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:28:09.202585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:28:09.205489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0909 14:28:15.581600 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0909 14:28:15.693711 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0909 14:28:36.663852 139966734747456 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Model has 315288 params
W0909 14:29:06.400333 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:173: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0909 14:29:06.431694 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:213: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

--------------------------------------------------------------------------------
Build valid graph
Tensor("child_1/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build test graph
Tensor("child_2/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build valid graph on shuffled data
Tensor("child_3/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
<tf.Variable 'controller/lstm/layer_0/w:0' shape=(128, 256) dtype=float32_ref>
<tf.Variable 'controller/g_emb:0' shape=(1, 64) dtype=float32_ref>
<tf.Variable 'controller/emb/w:0' shape=(6, 64) dtype=float32_ref>
<tf.Variable 'controller/softmax/w:0' shape=(64, 6) dtype=float32_ref>
<tf.Variable 'controller/attention/w_1:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/w_2:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/v:0' shape=(64, 1) dtype=float32_ref>
W0909 14:29:47.401185 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:185: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0909 14:29:47.416127 139966734747456 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:218: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0909 14:29:47.416520 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:231: SyncReplicasOptimizer.__init__ (from tensorflow.python.training.sync_replicas_optimizer) is deprecated and will be removed in a future version.
Instructions for updating:
The `SyncReplicaOptimizer` class is deprecated. For synchrononous training, please use [Distribution Strategies](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).
I0909 14:29:47.416672 139966734747456 sync_replicas_optimizer.py:188] SyncReplicasV2: replicas_to_aggregate=20; total_num_replicas=1
W0909 14:29:49.670617 139966734747456 deprecation_wrapper.py:119] From src/chess/main.py:239: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0909 14:29:52.195366 139966734747456 deprecation_wrapper.py:119] From src/chess/main.py:240: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.

I0909 14:29:52.196009 139966734747456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
--------------------------------------------------------------------------------
Starting session
I0909 14:30:25.920006 139966734747456 monitored_session.py:240] Graph was finalized.
2019-09-09 14:30:25.922903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:30:25.923028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:30:25.923059: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:30:25.923083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:30:25.923107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:30:25.923128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:30:25.923151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:30:25.923175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:30:25.925377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:30:25.925445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:30:25.925461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:30:25.925470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:30:25.927835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-09-09 14:30:36.740502: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0909 14:30:42.607570 139966734747456 session_manager.py:500] Running local_init_op.
I0909 14:30:44.303808 139966734747456 session_manager.py:502] Done running local_init_op.
W0909 14:30:49.348172 139966734747456 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
2019-09-09 14:33:42.485371: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:33:42.520098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:33:42.744109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44d89c0 executing computations on platform CUDA. Devices:
2019-09-09 14:33:42.744171: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:33:42.765091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:33:42.766370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41b58e0 executing computations on platform Host. Devices:
2019-09-09 14:33:42.766411: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:33:42.767769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:33:42.768229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:33:42.770955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:33:42.773300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:33:42.773862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:33:42.777051: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:33:42.779383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:33:42.785455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:33:42.787487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:33:42.787545: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:33:42.789021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:33:42.789049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:33:42.789060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:33:42.791222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 95 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:33:42.792518 140295986784064 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 6226145403868038650
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 11353681900949086864
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 5076429309522704372
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 100139008
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 6069954619313724823
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
213193
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0909 14:33:44.755558 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0909 14:33:47.261586 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:33:47.263972 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:33:47.333464 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0909 14:33:47.683295 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0909 14:33:48.201869 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0909 14:33:48.202652 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0909 14:33:48.309894 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0909 14:33:48.402428 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0909 14:33:50.410726 140295986784064 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0909 14:33:50.426256 140295986784064 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0909 14:33:50.449136 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0909 14:33:50.636350 140295986784064 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0909 14:33:50.786682 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-09 14:33:51.921724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:33:51.921917: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:33:51.921945: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:33:51.921963: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:33:51.921980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:33:51.921996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:33:51.922012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:33:51.922029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:33:51.925102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:33:51.925182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:33:51.925197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:33:51.925207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:33:51.927356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0909 14:33:53.283462 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0909 14:33:53.388246 140295986784064 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0909 14:34:14.227645 140295986784064 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Model has 315288 params
./scripts/chess_macro_search.sh : ligne 40 : 20854 Complété              python src/chess/main.py --data_format="NCHW" --search_for="macro" --reset_output_dir --data_path="data/chess" --output_dir="outputs" --batch_size=128 --num_epochs=310 --log_every=50 --eval_every_epochs=1 --child_use_aux_heads --child_num_layers=12 --child_out_filters=36 --child_l2_reg=0.00025 --child_num_branches=6 --child_num_cell_layers=5 --child_keep_prob=0.90 --child_drop_path_keep_prob=0.60 --child_lr_cosine --child_lr_max=0.05 --child_lr_min=0.0005 --child_lr_T_0=10 --child_lr_T_mul=2 --controller_training --controller_search_whole_channels --controller_entropy_weight=0.0001 --controller_train_every=1 --controller_sync_replicas --controller_num_aggregate=20 --controller_train_steps=50 --controller_lr=0.001 --controller_tanh_constant=1.5 --controller_op_tanh_reduce=2.5 --controller_skip_target=0.4 --controller_skip_weight=0.8 "$@"
2019-09-09 14:34:32.888446: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:34:32.920994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:34:33.152563: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3eb6d20 executing computations on platform CUDA. Devices:
2019-09-09 14:34:33.152623: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:34:33.177090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:34:33.178442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3b93b60 executing computations on platform Host. Devices:
2019-09-09 14:34:33.178481: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:34:33.179839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:34:33.372082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:34:33.374303: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:34:33.376164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:34:33.376616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:34:33.379206: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:34:33.381162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:34:33.387028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:34:33.389158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:34:33.389216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:34:33.390827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:34:33.390861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:34:33.390873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:34:33.394471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 95 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:34:33.395677 140043523553088 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 11391381214802959753
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 9100883529201320313
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 11568364852328277211
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 100139008
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 7618332593404468829
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
213193
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0909 14:34:35.867645 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0909 14:34:38.373240 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:34:38.375600 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:34:38.445048 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0909 14:34:38.805249 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0909 14:34:39.334720 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0909 14:34:39.335491 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0909 14:34:39.442759 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0909 14:34:39.535264 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0909 14:34:41.548898 140043523553088 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0909 14:34:41.566788 140043523553088 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0909 14:34:41.589848 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0909 14:34:41.774924 140043523553088 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0909 14:34:41.924965 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-09 14:34:43.010349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:34:43.010487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:34:43.010517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:34:43.010541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:34:43.010563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:34:43.010584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:34:43.010604: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:34:43.010626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:34:43.012566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:34:43.012634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:34:43.012650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:34:43.012660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:34:43.016033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0909 14:34:44.369122 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0909 14:34:44.473429 140043523553088 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
./scripts/chess_macro_search.sh : ligne 40 : 20931 Complété              python src/chess/main.py --data_format="NCHW" --search_for="macro" --reset_output_dir --data_path="data/chess" --output_dir="outputs" --batch_size=128 --num_epochs=310 --log_every=50 --eval_every_epochs=1 --child_use_aux_heads --child_num_layers=12 --child_out_filters=36 --child_l2_reg=0.00025 --child_num_branches=6 --child_num_cell_layers=5 --child_keep_prob=0.90 --child_drop_path_keep_prob=0.60 --child_lr_cosine --child_lr_max=0.05 --child_lr_min=0.0005 --child_lr_T_0=10 --child_lr_T_mul=2 --controller_training --controller_search_whole_channels --controller_entropy_weight=0.0001 --controller_train_every=1 --controller_sync_replicas --controller_num_aggregate=20 --controller_train_steps=50 --controller_lr=0.001 --controller_tanh_constant=1.5 --controller_op_tanh_reduce=2.5 --controller_skip_target=0.4 --controller_skip_weight=0.8 "$@"
I0909 14:34:55.221318 139966734747456 basic_session_run_hooks.py:606] Saving checkpoints for 0 into outputs/model.ckpt.
2019-09-09 14:35:43.419554: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:35:44.377830: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
epoch=0     ch_step=50     loss=1.093400 lr=0.0500   |g|=0.6279   tr_acc=42 /128 mins=0.42      
epoch=0     ch_step=100    loss=1.009657 lr=0.0500   |g|=0.3839   tr_acc=64 /128 mins=0.49      
epoch=0     ch_step=150    loss=1.035578 lr=0.0500   |g|=0.3604   tr_acc=53 /128 mins=0.56      
epoch=0     ch_step=200    loss=0.976500 lr=0.0500   |g|=0.2852   tr_acc=53 /128 mins=0.63      
epoch=0     ch_step=250    loss=0.971762 lr=0.0500   |g|=0.4111   tr_acc=56 /128 mins=0.70      
epoch=0     ch_step=300    loss=0.999984 lr=0.0500   |g|=0.2887   tr_acc=61 /128 mins=0.77      
epoch=0     ch_step=350    loss=0.994924 lr=0.0500   |g|=0.3124   tr_acc=66 /128 mins=0.84      
epoch=0     ch_step=400    loss=1.043134 lr=0.0500   |g|=0.3204   tr_acc=51 /128 mins=0.91      
epoch=0     ch_step=450    loss=0.980793 lr=0.0500   |g|=0.3110   tr_acc=57 /128 mins=0.98      
epoch=0     ch_step=500    loss=0.976118 lr=0.0500   |g|=0.3547   tr_acc=51 /128 mins=1.06      
epoch=0     ch_step=550    loss=0.996521 lr=0.0500   |g|=0.2922   tr_acc=50 /128 mins=1.13      
epoch=0     ch_step=600    loss=1.002321 lr=0.0500   |g|=0.3330   tr_acc=55 /128 mins=1.20      
epoch=0     ch_step=650    loss=1.051902 lr=0.0500   |g|=0.3348   tr_acc=58 /128 mins=1.27      
epoch=0     ch_step=700    loss=1.036640 lr=0.0500   |g|=0.2577   tr_acc=50 /128 mins=1.34      
epoch=0     ch_step=750    loss=1.057173 lr=0.0500   |g|=0.3268   tr_acc=40 /128 mins=1.41      
epoch=0     ch_step=800    loss=1.092475 lr=0.0500   |g|=0.3338   tr_acc=48 /128 mins=1.48      
epoch=0     ch_step=850    loss=1.049117 lr=0.0500   |g|=0.2514   tr_acc=56 /128 mins=1.56      
Traceback (most recent call last):
  File "src/chess/main.py", line 16, in <module>
    from src.chess.data_utils import read_data
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 30
    num_valids = len(boards["train"]))*0.1
                                     ^
SyntaxError: invalid syntax
epoch=0     ch_step=900    loss=1.058166 lr=0.0500   |g|=0.2799   tr_acc=60 /128 mins=1.63      
epoch=0     ch_step=950    loss=0.963750 lr=0.0500   |g|=0.2509   tr_acc=65 /128 mins=1.70      
epoch=0     ch_step=1000   loss=1.017039 lr=0.0500   |g|=0.2614   tr_acc=53 /128 mins=1.77      
epoch=0     ch_step=1050   loss=1.013320 lr=0.0500   |g|=0.2453   tr_acc=58 /128 mins=1.84      
epoch=0     ch_step=1100   loss=1.023506 lr=0.0500   |g|=0.2754   tr_acc=56 /128 mins=1.92      
epoch=0     ch_step=1150   loss=1.030300 lr=0.0500   |g|=0.2184   tr_acc=54 /128 mins=1.99      
epoch=0     ch_step=1200   loss=0.941527 lr=0.0500   |g|=0.2340   tr_acc=58 /128 mins=2.06      
epoch=0     ch_step=1250   loss=1.056762 lr=0.0500   |g|=0.2648   tr_acc=58 /128 mins=2.13      
epoch=0     ch_step=1300   loss=1.098493 lr=0.0500   |g|=0.3013   tr_acc=59 /128 mins=2.20      
epoch=0     ch_step=1350   loss=1.032934 lr=0.0500   |g|=0.2123   tr_acc=50 /128 mins=2.27      
epoch=0     ch_step=1400   loss=1.032517 lr=0.0500   |g|=0.2096   tr_acc=51 /128 mins=2.34      
epoch=0     ch_step=1450   loss=0.989754 lr=0.0500   |g|=0.2069   tr_acc=56 /128 mins=2.41      
epoch=0     ch_step=1500   loss=1.014176 lr=0.0500   |g|=0.2164   tr_acc=63 /128 mins=2.48      
I0909 14:37:57.497231 139966734747456 basic_session_run_hooks.py:606] Saving checkpoints for 1510 into outputs/model.ckpt.
Epoch 1: Training controller
./scripts/chess_macro_search.sh : ligne 40 : 20553 Complété              python src/chess/main.py --data_format="NCHW" --search_for="macro" --reset_output_dir --data_path="data/chess" --output_dir="outputs" --batch_size=128 --num_epochs=310 --log_every=50 --eval_every_epochs=1 --child_use_aux_heads --child_num_layers=12 --child_out_filters=36 --child_l2_reg=0.00025 --child_num_branches=6 --child_num_cell_layers=5 --child_keep_prob=0.90 --child_drop_path_keep_prob=0.60 --child_lr_cosine --child_lr_max=0.05 --child_lr_min=0.0005 --child_lr_T_0=10 --child_lr_T_mul=2 --controller_training --controller_search_whole_channels --controller_entropy_weight=0.0001 --controller_train_every=1 --controller_sync_replicas --controller_num_aggregate=20 --controller_train_steps=50 --controller_lr=0.001 --controller_tanh_constant=1.5 --controller_op_tanh_reduce=2.5 --controller_skip_target=0.4 --controller_skip_weight=0.8 "$@"
Traceback (most recent call last):
  File "src/chess/main.py", line 16, in <module>
    from src.chess.data_utils import read_data
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 30
    num_valids = len(boards["train"]))*0.1
                                     ^
SyntaxError: invalid syntax
2019-09-09 14:39:08.588101: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:39:08.624725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:39:08.888489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c08230 executing computations on platform CUDA. Devices:
2019-09-09 14:39:08.888562: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:39:08.909114: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:39:08.910685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4718580 executing computations on platform Host. Devices:
2019-09-09 14:39:08.910738: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:39:08.912396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:39:08.912885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:39:08.915445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:39:08.917625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:39:08.918175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:39:08.921214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:39:08.923111: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:39:08.928909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:39:08.931370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:39:08.931429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:39:08.933121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:39:08.933152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:39:08.933164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:39:08.935946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:39:08.937147 140017353197376 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 8213512593988065644
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 12880276897563175629
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 10461659813753119015
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 12750883771060171313
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
21319.300000000003
Traceback (most recent call last):
  File "src/chess/main.py", line 395, in <module>
    tf.app.run()
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "src/chess/main.py", line 384, in main
    train()
  File "src/chess/main.py", line 229, in train
    images, labels = read_data(FLAGS.data_path)
  File "/home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/data_utils.py", line 35, in read_data
    boards["valid"] = boards["train"][-num_valids:]
TypeError: slice indices must be integers or None or have an __index__ method
Exception ignored in: <src.utils.Logger object at 0x7f57ef71af60>
AttributeError: 'Logger' object has no attribute 'flush'
2019-09-09 14:40:20.958592: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-09 14:40:20.997816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-09 14:40:21.244686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5280740 executing computations on platform CUDA. Devices:
2019-09-09 14:40:21.244761: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-09 14:40:21.269143: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1598060000 Hz
2019-09-09 14:40:21.270540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f5d650 executing computations on platform Host. Devices:
2019-09-09 14:40:21.270581: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-09 14:40:21.272320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:40:21.272758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:40:21.275367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:40:21.277521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:40:21.278050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:40:21.281069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:40:21.283373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:40:21.290105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:40:21.292648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:40:21.292706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:40:21.294415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:40:21.294442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:40:21.294453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:40:21.297322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0909 14:40:21.298644 139697978992448 deprecation_wrapper.py:119] From src/chess/main.py:395: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

--------------------------------------------------------------------------------
CUDA VISIBLE DEVICES
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 3779625014408016615
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 1853865539724448865
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 16269335333510894952
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 10979036365
locality {
  bus_id: 2
  numa_node: 1
  links {
  }
}
incarnation: 13785308348196602459
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1"
]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Path outputs exists. Remove and remake.
--------------------------------------------------------------------------------
Logging to outputs/stdout
--------------------------------------------------------------------------------
batch_size...................................................................128
child_block_size...............................................................3
child_cutout_size...........................................................None
child_drop_path_keep_prob....................................................0.6
child_filter_size..............................................................5
child_fixed_arc.............................................................None
child_grad_bound.............................................................5.0
child_keep_prob..............................................................0.9
child_l2_reg.............................................................0.00025
child_lr.....................................................................0.1
child_lr_T_0..................................................................10
child_lr_T_mul.................................................................2
child_lr_cosine.............................................................True
child_lr_dec_every...........................................................100
child_lr_dec_rate............................................................0.1
child_lr_max................................................................0.05
child_lr_min..............................................................0.0005
child_num_aggregate.........................................................None
child_num_branches.............................................................6
child_num_cells................................................................5
child_num_layers..............................................................12
child_num_replicas.............................................................1
child_out_filters.............................................................36
child_out_filters_scale........................................................1
child_skip_pattern..........................................................None
child_sync_replicas........................................................False
child_use_aux_heads.........................................................True
controller_bl_dec...........................................................0.99
controller_entropy_weight.................................................0.0001
controller_forwards_limit......................................................2
controller_keep_prob.........................................................0.5
controller_l2_reg............................................................0.0
controller_lr..............................................................0.001
controller_lr_dec_rate.......................................................1.0
controller_num_aggregate......................................................20
controller_num_replicas........................................................1
controller_op_tanh_reduce....................................................2.5
controller_search_whole_channels............................................True
controller_skip_target.......................................................0.4
controller_skip_weight.......................................................0.8
controller_sync_replicas....................................................True
controller_tanh_constant.....................................................1.5
controller_temperature......................................................None
controller_train_every.........................................................1
controller_train_steps........................................................50
controller_training.........................................................True
controller_use_critic......................................................False
data_format.................................................................NCHW
data_path.............................................................data/chess
eval_every_epochs..............................................................1
log_every.....................................................................50
num_epochs...................................................................310
output_dir...............................................................outputs
reset_output_dir............................................................True
search_for.................................................................macro
--------------------------------------------------------------------------------
Reading data
Loading data ...
Loading data for chess_games_2000
Loading data for chess_games_2001
Loading data for chess_games_2002
Loading data for chess_games_2003
Loading data for chess_games_2004
21319
Loading data ...
Loading data for chess_games_2005
--------------------------------------------------------------------------------
Build model child
Build data ops
W0909 14:40:23.196260 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:83: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0909 14:40:25.921928 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:40:25.924023 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0909 14:40:25.993249 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:95: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0909 14:40:26.433100 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/models.py:142: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
--------------------------------------------------------------------------------
Building ConvController
W0909 14:40:27.068312 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0909 14:40:27.069083 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:96: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

--------------------------------------------------------------------------------
Build controller sampler
W0909 14:40:27.181354 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:184: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
W0909 14:40:27.276964 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_controller.py:278: The name tf.log is deprecated. Please use tf.math.log instead.

--------------------------------------------------------------------------------
Build train graph
Tensor("map/TensorArrayStack/TensorArrayGatherV3:0", shape=(?, 7, 8, 8), dtype=float32)
W0909 14:40:29.404924 139697978992448 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0909 14:40:29.420697 139697978992448 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:115: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0909 14:40:29.443514 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:134: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

W0909 14:40:29.627497 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:176: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0909 14:40:29.780940 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/image_ops.py:216: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.

2019-09-09 14:40:30.906225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:40:30.906381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:40:30.906413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:40:30.906440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:40:30.906472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:40:30.906495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:40:30.906521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:40:30.906549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:40:30.909768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:40:30.909874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:40:30.909895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:40:30.909907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:40:30.912881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
W0909 14:40:32.582580 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

W0909 14:40:32.686616 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Tensor("child/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_1/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_2/skip/bn/Identity:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child/layer_3/pool_at_3/from_4/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_4/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_5/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_6/skip/bn/Identity:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child/layer_7/pool_at_7/from_8/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_8/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_9/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_10/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child/layer_11/skip/bn/Identity:0", shape=(?, 36, 2, 2), dtype=float32)
W0909 14:40:53.818394 139697978992448 deprecation.py:506] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/chess/general_child.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Model has 315288 params
W0909 14:41:23.743902 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:173: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0909 14:41:23.775892 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:213: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

--------------------------------------------------------------------------------
Build valid graph
Tensor("child_1/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_1/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_1/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_1/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build test graph
Tensor("child_2/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_2/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_2/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_2/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
Build valid graph on shuffled data
Tensor("child_3/layer_0/case/cond/Merge:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_1/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_2/skip/bn/FusedBatchNorm:0", shape=(?, 36, 8, 8), dtype=float32)
Tensor("child_3/layer_3/pool_at_3/from_4/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_4/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_5/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_6/skip/bn/FusedBatchNorm:0", shape=(?, 36, 4, 4), dtype=float32)
Tensor("child_3/layer_7/pool_at_7/from_8/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_8/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_9/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_10/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
Tensor("child_3/layer_11/skip/bn/FusedBatchNorm:0", shape=(?, 36, 2, 2), dtype=float32)
--------------------------------------------------------------------------------
<tf.Variable 'controller/lstm/layer_0/w:0' shape=(128, 256) dtype=float32_ref>
<tf.Variable 'controller/g_emb:0' shape=(1, 64) dtype=float32_ref>
<tf.Variable 'controller/emb/w:0' shape=(6, 64) dtype=float32_ref>
<tf.Variable 'controller/softmax/w:0' shape=(64, 6) dtype=float32_ref>
<tf.Variable 'controller/attention/w_1:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/w_2:0' shape=(64, 64) dtype=float32_ref>
<tf.Variable 'controller/attention/v:0' shape=(64, 1) dtype=float32_ref>
W0909 14:42:04.107097 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:185: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0909 14:42:04.120639 139697978992448 deprecation_wrapper.py:119] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:218: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0909 14:42:04.120976 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/EfficientNeuralSearch/enas/src/utils.py:231: SyncReplicasOptimizer.__init__ (from tensorflow.python.training.sync_replicas_optimizer) is deprecated and will be removed in a future version.
Instructions for updating:
The `SyncReplicaOptimizer` class is deprecated. For synchrononous training, please use [Distribution Strategies](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).
I0909 14:42:04.121137 139697978992448 sync_replicas_optimizer.py:188] SyncReplicasV2: replicas_to_aggregate=20; total_num_replicas=1
W0909 14:42:06.298700 139697978992448 deprecation_wrapper.py:119] From src/chess/main.py:239: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0909 14:42:08.752123 139697978992448 deprecation_wrapper.py:119] From src/chess/main.py:240: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.

I0909 14:42:08.752704 139697978992448 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
--------------------------------------------------------------------------------
Starting session
I0909 14:42:41.409366 139697978992448 monitored_session.py:240] Graph was finalized.
2019-09-09 14:42:41.413095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-09-09 14:42:41.413234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-09 14:42:41.413269: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:42:41.413295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-09 14:42:41.413322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-09 14:42:41.413344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-09 14:42:41.413370: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-09 14:42:41.413396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-09 14:42:41.416801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-09 14:42:41.416885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-09 14:42:41.416904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-09 14:42:41.416916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-09 14:42:41.419976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-09-09 14:42:51.689377: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0909 14:42:57.572827 139697978992448 session_manager.py:500] Running local_init_op.
I0909 14:42:59.085602 139697978992448 session_manager.py:502] Done running local_init_op.
W0909 14:43:03.848453 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
I0909 14:47:14.783263 139697978992448 basic_session_run_hooks.py:606] Saving checkpoints for 0 into outputs/model.ckpt.
2019-09-09 14:48:05.043780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 14:48:05.508582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
epoch=0     ch_step=50     loss=1.020800 lr=0.0500   |g|=0.3780   tr_acc=58 /128 mins=0.40      
epoch=0     ch_step=100    loss=1.033161 lr=0.0500   |g|=0.3976   tr_acc=59 /128 mins=0.47      
epoch=0     ch_step=150    loss=1.037221 lr=0.0500   |g|=0.3224   tr_acc=58 /128 mins=0.54      
epoch=0     ch_step=200    loss=0.997642 lr=0.0500   |g|=0.2816   tr_acc=58 /128 mins=0.61      
epoch=0     ch_step=250    loss=1.035006 lr=0.0500   |g|=0.4393   tr_acc=54 /128 mins=0.69      
epoch=0     ch_step=300    loss=1.048756 lr=0.0500   |g|=0.3317   tr_acc=56 /128 mins=0.76      
epoch=0     ch_step=350    loss=1.060938 lr=0.0500   |g|=0.4691   tr_acc=56 /128 mins=0.83      
epoch=0     ch_step=400    loss=1.011081 lr=0.0500   |g|=0.2820   tr_acc=62 /128 mins=0.91      
epoch=0     ch_step=450    loss=1.006034 lr=0.0500   |g|=0.2595   tr_acc=47 /128 mins=0.98      
epoch=0     ch_step=500    loss=1.023798 lr=0.0500   |g|=0.3058   tr_acc=61 /128 mins=1.05      
epoch=0     ch_step=550    loss=0.998318 lr=0.0500   |g|=0.2621   tr_acc=74 /128 mins=1.12      
epoch=0     ch_step=600    loss=0.932003 lr=0.0500   |g|=0.3320   tr_acc=71 /128 mins=1.20      
epoch=0     ch_step=650    loss=0.972724 lr=0.0500   |g|=0.1884   tr_acc=57 /128 mins=1.27      
epoch=0     ch_step=700    loss=0.984638 lr=0.0500   |g|=0.2816   tr_acc=57 /128 mins=1.34      
epoch=0     ch_step=750    loss=1.013769 lr=0.0500   |g|=0.2514   tr_acc=52 /128 mins=1.41      
epoch=0     ch_step=800    loss=0.973643 lr=0.0500   |g|=0.2295   tr_acc=57 /128 mins=1.49      
epoch=0     ch_step=850    loss=1.057354 lr=0.0500   |g|=0.2869   tr_acc=52 /128 mins=1.56      
epoch=0     ch_step=900    loss=1.116635 lr=0.0500   |g|=0.3838   tr_acc=49 /128 mins=1.63      
epoch=0     ch_step=950    loss=1.000147 lr=0.0500   |g|=0.2437   tr_acc=67 /128 mins=1.70      
epoch=0     ch_step=1000   loss=0.996831 lr=0.0500   |g|=0.2688   tr_acc=61 /128 mins=1.77      
epoch=0     ch_step=1050   loss=1.029310 lr=0.0500   |g|=0.2568   tr_acc=63 /128 mins=1.85      
epoch=0     ch_step=1100   loss=1.009558 lr=0.0500   |g|=0.2180   tr_acc=49 /128 mins=1.92      
epoch=0     ch_step=1150   loss=0.976792 lr=0.0500   |g|=0.2177   tr_acc=52 /128 mins=1.99      
epoch=0     ch_step=1200   loss=1.006104 lr=0.0500   |g|=0.2572   tr_acc=51 /128 mins=2.07      
epoch=0     ch_step=1250   loss=1.018392 lr=0.0500   |g|=0.2083   tr_acc=53 /128 mins=2.14      
epoch=0     ch_step=1300   loss=0.979610 lr=0.0500   |g|=0.2259   tr_acc=57 /128 mins=2.21      
epoch=0     ch_step=1350   loss=1.071815 lr=0.0500   |g|=0.2386   tr_acc=48 /128 mins=2.29      
epoch=0     ch_step=1400   loss=1.023593 lr=0.0500   |g|=0.2270   tr_acc=56 /128 mins=2.36      
epoch=0     ch_step=1450   loss=1.039104 lr=0.0500   |g|=0.2502   tr_acc=54 /128 mins=2.43      
I0909 14:50:19.360740 139697978992448 basic_session_run_hooks.py:606] Saving checkpoints for 1500 into outputs/model.ckpt.
epoch=1     ch_step=1500   loss=1.062207 lr=0.0500   |g|=0.2235   tr_acc=55 /128 mins=2.73      
Epoch 1: Training controller
ctrl_step=0      loss=24.202  ent=26.46 lr=0.0010 |g|=0.4572   acc=0.3594 bl=0.00  mins=2.85
ctrl_step=2      loss=16.239  ent=26.46 lr=0.0010 |g|=0.2588   acc=0.4062 bl=0.17  mins=2.90
ctrl_step=5      loss=13.771  ent=26.46 lr=0.0010 |g|=0.2101   acc=0.4688 bl=0.27  mins=2.94
ctrl_step=7      loss=8.153   ent=26.46 lr=0.0010 |g|=0.1102   acc=0.4453 bl=0.33  mins=2.98
ctrl_step=10     loss=0.898   ent=26.46 lr=0.0010 |g|=0.0279   acc=0.3750 bl=0.37  mins=3.03
ctrl_step=12     loss=1.926   ent=26.46 lr=0.0010 |g|=0.0399   acc=0.4141 bl=0.39  mins=3.07
ctrl_step=15     loss=3.583   ent=26.46 lr=0.0010 |g|=0.0351   acc=0.4531 bl=0.40  mins=3.11
ctrl_step=17     loss=0.744   ent=26.46 lr=0.0010 |g|=0.0219   acc=0.4219 bl=0.41  mins=3.15
ctrl_step=20     loss=-1.472  ent=26.46 lr=0.0010 |g|=0.0288   acc=0.3906 bl=0.42  mins=3.19
ctrl_step=22     loss=-1.535  ent=26.46 lr=0.0010 |g|=0.0443   acc=0.3906 bl=0.42  mins=3.24
ctrl_step=25     loss=2.369   ent=26.45 lr=0.0010 |g|=0.0486   acc=0.4531 bl=0.42  mins=3.28
ctrl_step=27     loss=-4.186  ent=26.46 lr=0.0010 |g|=0.0789   acc=0.3516 bl=0.42  mins=3.32
ctrl_step=30     loss=-1.703  ent=26.45 lr=0.0010 |g|=0.0279   acc=0.3906 bl=0.42  mins=3.37
ctrl_step=32     loss=5.794   ent=26.45 lr=0.0010 |g|=0.0953   acc=0.5078 bl=0.42  mins=3.41
ctrl_step=35     loss=-2.511  ent=26.46 lr=0.0010 |g|=0.0564   acc=0.3828 bl=0.42  mins=3.45
ctrl_step=37     loss=7.405   ent=26.46 lr=0.0010 |g|=0.0942   acc=0.5312 bl=0.42  mins=3.49
ctrl_step=40     loss=0.974   ent=26.43 lr=0.0010 |g|=0.0567   acc=0.4297 bl=0.42  mins=3.54
ctrl_step=42     loss=-1.255  ent=26.47 lr=0.0010 |g|=0.0483   acc=0.3984 bl=0.42  mins=3.58
ctrl_step=45     loss=-3.787  ent=26.45 lr=0.0010 |g|=0.0638   acc=0.3594 bl=0.42  mins=3.62
ctrl_step=47     loss=-1.513  ent=26.46 lr=0.0010 |g|=0.0526   acc=0.3906 bl=0.42  mins=3.66
Here are 10 architectures
[3]
[2 0]
[0 0 1]
[2 0 1 1]
[1 0 0 1 0]
[2 1 0 1 0 0]
[4 0 0 0 0 1 1]
[1 1 1 1 0 0 1 1]
[1 0 1 1 1 0 1 1 1]
[2 1 0 0 1 0 0 1 0 1]
[4 1 0 1 0 0 1 0 1 0 1]
[5 1 0 0 1 1 1 0 1 0 0 1]
val_acc=0.4531
--------------------------------------------------------------------------------
[3]
[2 0]
[0 0 0]
[2 1 1 1]
[0 1 0 0 0]
[1 0 1 1 1 1]
[0 1 0 1 1 1 1]
[5 1 1 0 1 0 0 0]
[4 1 0 1 0 0 1 0 1]
[0 0 0 1 0 1 1 0 1 0]
[3 0 1 1 1 0 0 0 0 0 0]
[3 0 0 1 1 0 1 0 1 1 0 1]
val_acc=0.4453
--------------------------------------------------------------------------------
[5]
[3 1]
[2 1 1]
[0 0 1 0]
[2 0 1 0 0]
[1 0 1 1 0 1]
[5 0 1 0 1 1 1]
[0 0 1 1 1 1 0 0]
[3 1 0 1 1 0 1 0 1]
[4 0 0 1 0 0 0 1 0 0]
[0 1 0 1 0 0 0 1 0 0 1]
[4 1 1 0 1 1 1 1 0 0 1 1]
val_acc=0.3672
--------------------------------------------------------------------------------
[5]
[5 1]
[2 1 1]
[1 1 0 0]
[2 1 1 1 1]
[1 1 1 1 0 0]
[2 1 0 0 1 0 1]
[2 1 0 0 1 1 1 0]
[0 1 1 0 0 1 0 1 0]
[3 0 0 0 0 0 0 0 0 1]
[4 0 0 0 0 0 0 0 1 1 0]
[1 0 1 1 0 1 0 1 0 1 1 0]
val_acc=0.4375
--------------------------------------------------------------------------------
[1]
[2 0]
[5 0 1]
[4 1 1 0]
[1 0 1 1 0]
[4 0 0 0 1 1]
[4 1 1 1 0 1 0]
[4 0 1 1 0 0 0 1]
[3 0 0 1 0 0 1 0 0]
[1 1 0 0 0 1 1 1 0 0]
[2 1 1 0 0 1 1 0 1 0 0]
[3 1 0 1 0 1 0 0 1 0 1 1]
val_acc=0.4922
--------------------------------------------------------------------------------
[5]
[5 0]
[4 0 1]
[4 1 0 1]
[4 1 1 1 0]
[4 1 0 1 0 0]
[2 1 0 0 1 1 1]
[2 0 1 1 1 1 0 1]
[4 0 1 1 0 1 0 0 1]
[1 1 1 0 0 0 1 0 1 1]
[2 0 1 1 1 0 0 0 0 0 1]
[1 0 1 0 1 0 1 0 0 0 1 0]
val_acc=0.4141
--------------------------------------------------------------------------------
[0]
[2 0]
[0 0 1]
[5 1 0 0]
[2 1 1 0 1]
[4 1 0 0 0 0]
[4 1 0 1 1 1 0]
[4 1 0 1 1 0 0 0]
[5 0 0 1 1 0 0 1 1]
[3 0 1 0 0 0 1 0 0 0]
[5 1 0 0 0 1 1 1 1 1 0]
[1 0 0 1 0 1 0 1 1 1 0 0]
val_acc=0.3828
--------------------------------------------------------------------------------
[5]
[4 0]
[1 1 0]
[5 1 0 0]
[4 0 1 0 0]
[5 1 1 1 1 0]
[5 1 0 1 1 1 1]
[4 0 0 0 1 0 0 0]
[2 1 1 0 0 0 1 0 1]
[1 0 1 1 1 0 1 0 1 0]
[3 0 1 1 1 1 0 1 0 1 1]
[3 1 1 1 1 1 1 1 0 0 1 0]
val_acc=0.4453
--------------------------------------------------------------------------------
[2]
[2 0]
[4 1 0]
[0 0 0 1]
[2 1 1 0 1]
[5 1 0 0 0 0]
[4 1 1 1 1 1 1]
[2 1 0 0 0 0 0 1]
[3 0 0 0 0 0 0 1 0]
[3 1 1 1 1 0 0 0 1 0]
[0 1 1 1 1 1 0 1 0 0 0]
[0 1 0 1 1 1 1 1 0 1 1 0]
val_acc=0.3672
--------------------------------------------------------------------------------
[2]
[5 1]
[0 0 0]
[1 0 1 0]
[1 1 0 0 0]
[2 1 0 0 1 1]
[0 1 1 0 0 1 0]
[5 1 1 0 1 0 0 0]
[4 0 0 1 0 0 1 1 0]
[1 1 1 1 0 0 1 1 1 1]
[5 0 1 1 1 0 1 0 1 0 0]
[1 0 0 1 1 0 1 0 0 1 1 0]
val_acc=0.4922
--------------------------------------------------------------------------------
Epoch 1: Eval
Eval at 1500
valid_eaccuracy: 0.4288
Eval at 1500
test_eaccuracy: 0.4439
epoch=1     ch_step=1550   loss=1.012111 lr=0.0488   |g|=0.2089   tr_acc=54 /128 mins=4.30      
epoch=1     ch_step=1600   loss=1.058423 lr=0.0488   |g|=0.3107   tr_acc=49 /128 mins=4.38      
epoch=1     ch_step=1650   loss=1.010349 lr=0.0488   |g|=0.1909   tr_acc=57 /128 mins=4.45      
epoch=1     ch_step=1700   loss=1.086776 lr=0.0488   |g|=0.3003   tr_acc=47 /128 mins=4.52      
epoch=1     ch_step=1750   loss=1.030651 lr=0.0488   |g|=0.2000   tr_acc=59 /128 mins=4.59      
epoch=1     ch_step=1800   loss=0.940360 lr=0.0488   |g|=0.2157   tr_acc=61 /128 mins=4.67      
epoch=1     ch_step=1850   loss=1.023747 lr=0.0488   |g|=0.1751   tr_acc=57 /128 mins=4.74      
epoch=1     ch_step=1900   loss=1.018152 lr=0.0488   |g|=0.2355   tr_acc=56 /128 mins=4.81      
epoch=1     ch_step=1950   loss=1.009931 lr=0.0488   |g|=0.1832   tr_acc=61 /128 mins=4.88      
epoch=1     ch_step=2000   loss=0.971149 lr=0.0488   |g|=0.2434   tr_acc=59 /128 mins=4.95      
epoch=1     ch_step=2050   loss=0.984550 lr=0.0488   |g|=0.1994   tr_acc=55 /128 mins=5.02      
epoch=1     ch_step=2100   loss=1.011344 lr=0.0488   |g|=0.2240   tr_acc=65 /128 mins=5.10      
epoch=1     ch_step=2150   loss=0.955523 lr=0.0488   |g|=0.1830   tr_acc=60 /128 mins=5.17      
epoch=1     ch_step=2200   loss=0.966843 lr=0.0488   |g|=0.2221   tr_acc=67 /128 mins=5.24      
epoch=1     ch_step=2250   loss=0.984290 lr=0.0488   |g|=0.2665   tr_acc=65 /128 mins=5.31      
epoch=1     ch_step=2300   loss=1.028372 lr=0.0488   |g|=0.1834   tr_acc=57 /128 mins=5.38      
epoch=1     ch_step=2350   loss=1.004447 lr=0.0488   |g|=0.1806   tr_acc=56 /128 mins=5.46      
epoch=1     ch_step=2400   loss=1.087720 lr=0.0488   |g|=0.2587   tr_acc=44 /128 mins=5.53      
epoch=1     ch_step=2450   loss=0.992010 lr=0.0488   |g|=0.3454   tr_acc=64 /128 mins=5.60      
epoch=1     ch_step=2500   loss=1.024875 lr=0.0488   |g|=0.2781   tr_acc=56 /128 mins=5.67      
epoch=1     ch_step=2550   loss=1.013689 lr=0.0488   |g|=0.2495   tr_acc=66 /128 mins=5.74      
epoch=1     ch_step=2600   loss=0.993622 lr=0.0488   |g|=0.2233   tr_acc=64 /128 mins=5.82      
epoch=1     ch_step=2650   loss=1.030061 lr=0.0488   |g|=0.2721   tr_acc=63 /128 mins=5.89      
epoch=1     ch_step=2700   loss=0.956047 lr=0.0488   |g|=0.2977   tr_acc=62 /128 mins=5.96      
epoch=1     ch_step=2750   loss=0.948732 lr=0.0488   |g|=0.2336   tr_acc=66 /128 mins=6.03      
epoch=1     ch_step=2800   loss=1.040614 lr=0.0488   |g|=0.2438   tr_acc=59 /128 mins=6.10      
epoch=1     ch_step=2850   loss=1.014655 lr=0.0488   |g|=0.2988   tr_acc=55 /128 mins=6.18      
epoch=1     ch_step=2900   loss=1.005742 lr=0.0488   |g|=0.2596   tr_acc=65 /128 mins=6.25      
epoch=1     ch_step=2950   loss=0.988164 lr=0.0488   |g|=0.2390   tr_acc=62 /128 mins=6.32      
I0909 14:54:12.602773 139697978992448 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into outputs/model.ckpt.
W0909 14:54:12.694599 139697978992448 deprecation.py:323] From /home/habreu/pv/lothair/venv_3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
epoch=2     ch_step=3000   loss=1.078629 lr=0.0488   |g|=0.2885   tr_acc=51 /128 mins=6.62      
Epoch 2: Training controller
ctrl_step=50     loss=1.261   ent=26.47 lr=0.0010 |g|=0.0397   acc=0.4375 bl=0.42  mins=6.62
ctrl_step=52     loss=-1.008  ent=26.46 lr=0.0010 |g|=0.0558   acc=0.4141 bl=0.43  mins=6.66
ctrl_step=55     loss=-2.890  ent=26.46 lr=0.0010 |g|=0.0648   acc=0.3906 bl=0.44  mins=6.70
ctrl_step=57     loss=1.729   ent=26.40 lr=0.0010 |g|=0.0880   acc=0.4688 bl=0.45  mins=6.75
ctrl_step=60     loss=-1.372  ent=26.39 lr=0.0010 |g|=0.0240   acc=0.4219 bl=0.45  mins=6.79
ctrl_step=62     loss=1.922   ent=26.48 lr=0.0010 |g|=0.0382   acc=0.4688 bl=0.44  mins=6.83
ctrl_step=65     loss=-3.320  ent=26.40 lr=0.0010 |g|=0.0548   acc=0.3906 bl=0.44  mins=6.87
ctrl_step=67     loss=0.040   ent=26.39 lr=0.0010 |g|=0.0656   acc=0.4453 bl=0.45  mins=6.92
ctrl_step=70     loss=1.578   ent=26.43 lr=0.0010 |g|=0.0652   acc=0.4609 bl=0.44  mins=6.96
ctrl_step=72     loss=1.493   ent=26.30 lr=0.0010 |g|=0.1256   acc=0.4609 bl=0.44  mins=7.00
ctrl_step=75     loss=2.273   ent=26.24 lr=0.0010 |g|=0.1847   acc=0.4766 bl=0.45  mins=7.04
ctrl_step=77     loss=-2.433  ent=26.35 lr=0.0010 |g|=0.1230   acc=0.4062 bl=0.45  mins=7.09
ctrl_step=80     loss=-0.474  ent=26.29 lr=0.0010 |g|=0.0911   acc=0.4297 bl=0.44  mins=7.13
ctrl_step=82     loss=4.971   ent=26.06 lr=0.0010 |g|=0.3448   acc=0.5156 bl=0.44  mins=7.17
ctrl_step=85     loss=-2.388  ent=26.29 lr=0.0010 |g|=0.2182   acc=0.4062 bl=0.45  mins=7.21
ctrl_step=87     loss=0.394   ent=25.72 lr=0.0010 |g|=0.1347   acc=0.4453 bl=0.44  mins=7.26
ctrl_step=90     loss=1.987   ent=25.63 lr=0.0010 |g|=0.2020   acc=0.4688 bl=0.44  mins=7.30
ctrl_step=92     loss=-2.381  ent=25.41 lr=0.0010 |g|=0.1540   acc=0.4062 bl=0.45  mins=7.34
ctrl_step=95     loss=3.003   ent=24.82 lr=0.0010 |g|=0.2987   acc=0.4922 bl=0.45  mins=7.38
ctrl_step=97     loss=0.607   ent=24.57 lr=0.0010 |g|=0.0810   acc=0.4531 bl=0.45  mins=7.43
Here are 10 architectures
[4]
[1 0]
[5 1 0]
[0 0 1 0]
[1 0 0 1 0]
[4 1 1 1 0 0]
[4 0 0 0 1 0 0]
[1 1 1 0 1 0 1 0]
[4 1 1 1 1 1 1 1 1]
[4 0 0 0 0 1 1 1 0 0]
[0 1 0 1 0 1 0 0 0 0 0]
[4 0 0 0 1 1 0 0 0 0 0 0]
val_acc=0.4531
--------------------------------------------------------------------------------
[5]
[5 0]
[0 0 1]
[0 0 1 1]
[0 0 1 0 1]
[1 0 0 0 0 0]
[3 0 1 0 1 0 0]
[5 0 1 1 0 1 0 1]
[1 0 0 1 0 1 0 1 1]
[4 1 0 0 0 0 0 0 0 0]
[2 1 0 0 1 1 0 1 1 1 1]
[3 0 0 1 1 0 0 0 1 1 0 0]
val_acc=0.4922
--------------------------------------------------------------------------------
[5]
[1 0]
[1 1 0]
[2 0 1 0]
[2 0 0 0 0]
[4 1 1 0 1 0]
[0 0 0 0 0 0 1]
[4 0 0 0 0 0 1 0]
[0 1 0 0 1 1 1 1 1]
[1 1 0 0 0 1 0 0 1 1]
[2 0 0 0 0 1 1 1 0 0 0]
[3 1 1 0 0 1 1 1 1 0 1 0]
val_acc=0.4297
--------------------------------------------------------------------------------
[3]
[2 0]
[4 1 1]
[0 0 1 1]
[3 0 1 0 0]
[5 0 0 1 0 1]
[5 0 0 1 0 1 0]
[4 1 0 0 0 1 1 0]
[3 0 0 1 1 0 1 0 0]
[5 1 0 0 1 0 1 0 1 1]
[3 1 0 0 0 0 0 0 0 0 0]
[0 0 1 0 0 0 0 1 0 0 0 0]
val_acc=0.3984
--------------------------------------------------------------------------------
[3]
[0 1]
[5 0 0]
[4 1 1 0]
[2 1 1 1 1]
[1 1 1 1 0 1]
[5 0 0 1 1 1 0]
[0 0 1 0 0 0 0 0]
[5 0 0 0 0 0 0 1 0]
[5 0 1 1 0 0 0 0 0 0]
[4 1 1 0 1 0 1 1 1 1 0]
[1 0 0 1 1 1 0 0 0 0 0 1]
val_acc=0.4219
--------------------------------------------------------------------------------
[2]
[1 0]
[4 0 1]
[5 1 0 0]
[3 0 1 1 0]
[0 0 0 0 0 1]
[0 0 0 1 0 1 0]
[0 0 1 0 1 1 1 0]
[1 0 1 1 0 1 1 0 1]
[2 1 0 0 0 1 0 0 1 0]
[1 1 0 1 0 1 0 1 0 1 0]
[3 0 0 1 0 0 0 0 1 1 0 0]
val_acc=0.4141
--------------------------------------------------------------------------------
[4]
[0 1]
[2 0 0]
[4 0 0 0]
[3 0 0 1 0]
[2 1 0 0 1 0]
[5 1 1 1 1 1 0]
[3 0 1 0 0 1 1 0]
[5 1 1 0 1 1 1 1 0]
[5 0 0 1 1 0 0 0 1 0]
[0 0 0 0 1 1 1 0 0 1 0]
[5 1 1 0 0 1 0 0 0 0 0 0]
val_acc=0.3672
--------------------------------------------------------------------------------
[0]
[1 1]
[1 0 0]
[1 0 0 1]
[4 1 0 1 0]
[0 0 0 0 1 1]
[5 1 0 1 0 1 1]
[5 0 0 1 0 1 1 1]
[2 1 0 1 0 0 1 0 0]
[2 0 0 0 0 1 0 0 1 1]
[2 0 1 0 1 0 0 0 0 0 0]
[4 1 1 0 0 0 0 0 0 1 1 0]
val_acc=0.4297
--------------------------------------------------------------------------------
[5]
[4 1]
[3 0 1]
[3 0 0 0]
[5 1 0 1 0]
[0 1 0 0 1 0]
[0 1 1 1 0 0 1]
[0 0 1 1 0 1 1 0]
[2 0 1 1 0 1 0 0 0]
[3 1 0 1 1 1 0 1 0 0]
[2 0 0 1 1 1 0 1 1 0 0]
[2 0 1 0 0 1 0 0 0 0 0 1]
val_acc=0.4453
--------------------------------------------------------------------------------
[5]
[1 1]
[2 0 0]
[3 1 1 0]
[1 0 0 0 1]
[3 1 0 0 1 0]
[5 0 0 0 0 0 0]
[4 0 1 1 0 1 1 1]
[4 1 1 0 1 0 1 0 0]
[3 1 1 1 0 0 0 0 1 0]
[1 0 1 1 1 0 1 0 1 1 0]
[3 0 0 1 0 0 0 0 1 0 1 1]
val_acc=0.4297
--------------------------------------------------------------------------------
Epoch 2: Eval
Eval at 3000
valid_eaccuracy: 0.4349
Eval at 3000
test_eaccuracy: 0.4313
epoch=2     ch_step=3050   loss=1.040893 lr=0.0453   |g|=0.3377   tr_acc=59 /128 mins=7.87      
epoch=2     ch_step=3100   loss=0.983552 lr=0.0453   |g|=0.2637   tr_acc=63 /128 mins=7.94      
epoch=2     ch_step=3150   loss=1.028622 lr=0.0453   |g|=0.3367   tr_acc=61 /128 mins=8.01      
epoch=2     ch_step=3200   loss=1.019655 lr=0.0453   |g|=0.3417   tr_acc=60 /128 mins=8.08      
epoch=2     ch_step=3250   loss=0.998971 lr=0.0453   |g|=0.2559   tr_acc=60 /128 mins=8.16      
epoch=2     ch_step=3300   loss=0.994113 lr=0.0453   |g|=0.2534   tr_acc=69 /128 mins=8.23      
